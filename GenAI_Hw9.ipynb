{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MntmiANZCk2L"
      },
      "source": [
        "# GenAI HW9: Quick Summary of Lecture Video (演講影片快速摘要)\n",
        "## Objectives\n",
        "- ### Learn to quickly build applications related to speech recognition using existing APIs. (學習以現成的API快速搭建語音辨識相關的應用。)\n",
        "\n",
        "\n",
        "#### If you have any questions, please contact the TAs via TA hours, NTU COOL, or email to ntu-gen-ai-2024-spring-ta@googlegroups.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voEioD2DCoeq"
      },
      "source": [
        "# Part1 - Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSccLtt234Pm"
      },
      "source": [
        "## The lecture video provided for this assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgHVz9WF4Vfp"
      },
      "source": [
        "(1) For ease of processing, it has already been converted to a MP3 file.\n",
        "\n",
        "(2) If you would like to view the original video, the link is here:\n",
        "\n",
        "- 李琳山教授 信號與人生 (2023)\n",
        "\n",
        "  - https://www.youtube.com/watch?v=MxoQV4M0jY8\n",
        "\n",
        "\n",
        "(3) Since the original lecture video is quite long, we have edited the segment from 1:43:24 to 2:00:49 to use for this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdoLJZE33oCD"
      },
      "source": [
        "## Install all necessary packages and import them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HREsIZV33yDy"
      },
      "source": [
        "The following code block takes about **150** seconds to run, but it may vary slightly depending on the condition of Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgL2wxdxCvA5",
        "outputId": "2818dfcc-1bf5-4a98-cc7e-dc2370d118b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-pkgt6ek4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-pkgt6ek4\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.14.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802826 sha256=e515f41ddf5828006bd0c79ebb467f82aaab35971227ed25fd89b436191925ed\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-62z3vc0m/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.7.0\n",
            "Collecting srt\n",
            "  Downloading srt-3.5.3.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: srt\n",
            "  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22428 sha256=3b9627b10b7a43508dc81c73aa602b3f2aa3334fbd72ef6920e090d9dddfe99b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/31/a1/18e1e7e8bfdafd19e6803d7eb919b563dd11de380e4304e332\n",
            "Successfully built srt\n",
            "Installing collected packages: srt\n",
            "Successfully installed srt-3.5.3\n",
            "Collecting datetime\n",
            "  Downloading DateTime-5.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zope.interface (from datetime)\n",
            "  Downloading zope.interface-6.4.post2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.8/247.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from datetime) (2023.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zope.interface->datetime) (67.7.2)\n",
            "Installing collected packages: zope.interface, datetime\n",
            "Successfully installed datetime-5.5 zope.interface-6.4.post2\n",
            "Collecting opencc\n",
            "  Downloading OpenCC-1.1.7-cp310-cp310-manylinux1_x86_64.whl (779 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.8/779.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencc\n",
            "Successfully installed opencc-1.1.7\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython) (67.7.2)\n",
            "Collecting jedi>=0.16 (from IPython)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython) (0.2.13)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.19.1\n",
            "Collecting openai\n",
            "  Downloading openai-1.30.3-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.3\n",
            "Collecting anthropic\n",
            "  Downloading anthropic-0.26.1-py3-none-any.whl (877 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m877.6/877.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.27.0)\n",
            "Collecting jiter<1,>=0.1.0 (from anthropic)\n",
            "  Downloading jiter-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (327 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.8/327.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.19.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.18.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic) (0.23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.0.7)\n",
            "Installing collected packages: jiter, anthropic\n",
            "Successfully installed anthropic-0.26.1 jiter-0.4.0\n"
          ]
        }
      ],
      "source": [
        "# Install packages.\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install srt\n",
        "!pip install datetime\n",
        "!pip install opencc\n",
        "!pip install datasets\n",
        "!pip install numpy\n",
        "!pip install soundfile\n",
        "!pip install IPython\n",
        "!pip install openai\n",
        "!pip install -q -U google-generativeai\n",
        "!pip install anthropic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWqXz6C6omR9"
      },
      "source": [
        "The following code block takes about **5** seconds to run, but it may vary slightly depending on the condition of Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JFwSa_x6C53S"
      },
      "outputs": [],
      "source": [
        "# Import packages.\n",
        "\n",
        "import whisper\n",
        "import srt\n",
        "import datetime\n",
        "import time\n",
        "import os\n",
        "import re\n",
        "import pathlib\n",
        "import textwrap\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from opencc import OpenCC\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "from openai import OpenAI\n",
        "import google.generativeai as genai\n",
        "import anthropic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFY6VDAyeooa"
      },
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBROu_HfgF1J"
      },
      "source": [
        "The code block below takes about **10** seconds to run, although there might be some slight variation depending on the state of Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235,
          "referenced_widgets": [
            "73e610aefcb24297b7798eea993d7a0e",
            "71cb28a87d46426c94b97b0dfa37a2f9",
            "ff8f1eef385a4e1d9edb79149f997488",
            "c0ec8184773a4aaa912316b8d350445b",
            "6cd53057125b4dbd9885d5458e03ebbf",
            "70800a5fbfe4436d82c428733a16aa60",
            "25d42064d33b49199a378017d46ea26a",
            "e4d0bdf7c9424aa399d26c66af28f938",
            "76ce9f593f174606842a56fcbd8b3fa7",
            "725f3b88f2fd4df2b38d76dbab599165",
            "9c472c36419744d996c8ad05f662526b",
            "72117f7544e441b38d5d910af445d785",
            "e3f62551a707485fab72d240fc4f8fe7",
            "40b44a98ac144c2794a585e0903eb960",
            "7ba16a3b19284863b52a0a3ba04bd668",
            "fa6f5e5f15854517851c141aaba69fec",
            "4a294271842a465c9843b1e0b4d55b2f",
            "006bb78e1a1a4456a25295caea262d63",
            "d261d016c5e34bb998b2f60a46681fc4",
            "cfdd4956c6244dfba7e524878532bb12",
            "b91d12ab1e114995be5063c3107f0bfb",
            "62829631d64b4402bd8d0185b268bf5f",
            "099dd6a79fee42a28d39cfb0984d1494",
            "efad0a1f7bf7412ba39d488428593af3",
            "fc78c9ef37544f26aa45ec4ae4ad0501",
            "86c2f797ac92442f93e80b390e6b70ad",
            "e9f84e42a9f645258245f40e71d6f4c3",
            "dac72638b91a4a2b9bda90cb2793e8d1",
            "8659b492a8404f86b1eb8b83a6af1678",
            "1c07953785b94210a1503cc3aa7e917f",
            "adf3e275a67c4ce39dc09abbba201358",
            "2f40912e59ad45eeb337a62ed8ab0d79",
            "5c323eec317a4cc283b7533ef25a4592"
          ]
        },
        "id": "PAieqtY8evUJ",
        "outputId": "c53f714f-f70b-449b-eca4-2c1db1a98046"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73e610aefcb24297b7798eea993d7a0e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/305 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72117f7544e441b38d5d910af445d785",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/3.14M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "099dd6a79fee42a28d39cfb0984d1494",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load dataset.\n",
        "dataset_name = \"kuanhuggingface/NTU-GenAI-2024-HW9\"\n",
        "dataset = load_dataset(dataset_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1pN3dOGyrI-"
      },
      "source": [
        "The code block below takes about **15** seconds to run, although there might be some slight variation depending on the state of Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E68E8Ej2isAX",
        "outputId": "f93c3c3a-e264-4150-8256-cae34e9be1f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Now, we are going to transcribe the audio: 李琳山教授 信號與人生 (2023) (ntu-gen-ai-2024-hw9-16k.mp3).\n"
          ]
        }
      ],
      "source": [
        "# Prepare audio.\n",
        "input_audio = dataset[\"test\"][\"audio\"][0]\n",
        "input_audio_name = input_audio[\"path\"]\n",
        "input_audio_array = input_audio[\"array\"].astype(np.float32)\n",
        "sampling_rate = input_audio[\"sampling_rate\"]\n",
        "\n",
        "print(f\"Now, we are going to transcribe the audio: 李琳山教授 信號與人生 (2023) ({input_audio_name}).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxTn1CfzDCXy"
      },
      "source": [
        "# Part2 - Automatic Speech Recognition (ASR)\n",
        "The function \"speech_recognition\" aims to convert audio to subtitle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OmWjjLUGC9z3"
      },
      "outputs": [],
      "source": [
        "def speech_recognition(model_name, input_audio, output_subtitle_path, decode_options, cache_dir=\"./\"):\n",
        "    '''\n",
        "        (1) Objective:\n",
        "            - This function aims to convert audio to subtitle.\n",
        "\n",
        "        (2) Arguments:\n",
        "\n",
        "            - model_name (str):\n",
        "                The name of the model. There are five model sizes, including tiny, base, small, medium, large-v3.\n",
        "                For example, you can use 'tiny', 'base', 'small', 'medium', 'large-v3' to specify the model name.\n",
        "                You can see 'https://github.com/openai/whisper' for more details.\n",
        "\n",
        "            - input_audio (Union[str, np.ndarray, torch.Tensor]):\n",
        "                The path to the audio file to open, or the audio waveform\n",
        "                - For example, if your input audio path is 'input.wav', you can use 'input.wav' to specify the input audio path.\n",
        "                - For example, if your input audio array is 'audio_array', you can use 'audio_array' to specify the input audio array.\n",
        "\n",
        "            - output_subtitle_path (str):\n",
        "                The path of the output subtitle file.\n",
        "                For example, if you want to save the subtitle file as 'output.srt', you can use 'output.srt' to specify the output subtitle path.\n",
        "\n",
        "            - decode_options (dict):\n",
        "                The options for decoding the audio file, including 'initial_prompt', 'prompt', 'prefix', 'temperature'.\n",
        "                - initial_prompt (str):\n",
        "                    Optional text to provide as a prompt for the first window. This can be used to provide, or\n",
        "                    \"prompt-engineer\" a context for transcription, e.g. custom vocabularies or proper nouns\n",
        "                    to make it more likely to predict those word correctly.\n",
        "                    Default: None.\n",
        "\n",
        "                You can see \"https://github.com/openai/whisper/blob/main/whisper/decoding.py\" and \"https://github.com/openai/whisper/blob/main/whisper/transcribe.py\"\n",
        "                for more details.\n",
        "\n",
        "                - temperature (float):\n",
        "                    The temperature for sampling from the model. Higher values mean more randomness.\n",
        "                    Default: 0.0\n",
        "\n",
        "            - cache_dir (str):\n",
        "                The path of the cache directory for saving the model.\n",
        "                For example, if you want to save the cache files in 'cache' directory, you can use 'cache' to specify the cache directory.\n",
        "                Default: './'\n",
        "\n",
        "        (3) Example:\n",
        "\n",
        "            - If you want to use the 'base' model to convert 'input.wav' to 'output.srt' and save the cache files in 'cache' directory,\n",
        "            you can call this function as follows:\n",
        "\n",
        "                speech_recognition(model_name='base', input_audio_path='input.wav', output_subtitle_path='output.srt', cache_dir='cache')\n",
        "    '''\n",
        "\n",
        "    # Record the start time.\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(f\"=============== Loading Whisper-{model_name} ===============\")\n",
        "\n",
        "    # Load the model.\n",
        "    model = whisper.load_model(name=model_name, download_root=cache_dir)\n",
        "\n",
        "    print(f\"Begin to utilize Whisper-{model_name} to transcribe the audio.\")\n",
        "\n",
        "    # Transcribe the audio.\n",
        "    transcription = model.transcribe(audio=input_audio, language=decode_options[\"language\"], verbose=False,\n",
        "                                     initial_prompt=decode_options[\"initial_prompt\"], temperature=decode_options[\"temperature\"])\n",
        "\n",
        "    # Record the end time.\n",
        "    end_time = time.time()\n",
        "\n",
        "    print(f\"The process of speech recognition costs {end_time - start_time} seconds.\")\n",
        "\n",
        "    subtitles = []\n",
        "    # Convert the transcription to subtitle and iterate over the segments.\n",
        "    for i, segment in tqdm(enumerate(transcription[\"segments\"])):\n",
        "\n",
        "        # Convert the start time to subtitle format.\n",
        "        start_time = datetime.timedelta(seconds=segment[\"start\"])\n",
        "\n",
        "        # Convert the end time to subtitle format.\n",
        "        end_time = datetime.timedelta(seconds=segment[\"end\"])\n",
        "\n",
        "        # Get the subtitle text.\n",
        "        text = segment[\"text\"]\n",
        "\n",
        "        # Append the subtitle to the subtitle list.\n",
        "        subtitles.append(srt.Subtitle(index=i, start=start_time, end=end_time, content=text))\n",
        "\n",
        "    # Convert the subtitle list to subtitle content.\n",
        "    srt_content = srt.compose(subtitles)\n",
        "\n",
        "    print(f\"\\n=============== Saving the subtitle to {output_subtitle_path} ===============\")\n",
        "\n",
        "    # Save the subtitle content to the subtitle file.\n",
        "    with open(output_subtitle_path, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(srt_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3ZkyefXpvmh"
      },
      "source": [
        "In the following block, you can modify your desired parameters and the path of input file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "UULEr1GpDAl6"
      },
      "outputs": [],
      "source": [
        "# @title Parameter Setting of Whisper { run: \"auto\" }\n",
        "\n",
        "''' In this block, you can modify your desired parameters and the path of input file. '''\n",
        "\n",
        "# The name of the model you want to use.\n",
        "# For example, you can use 'tiny', 'base', 'small', 'medium', 'large-v3' to specify the model name.\n",
        "# @markdown **model_name**: The name of the model you want to use.\n",
        "model_name = \"medium\" # @param [\"tiny\", \"base\", \"small\", \"medium\", \"large-v3\"]\n",
        "\n",
        "# Define the suffix of the output file.\n",
        "# @markdown **suffix**: The output file name is \"output-{suffix}.* \", where .* is the file extention (.txt or .srt)\n",
        "suffix = \"信號與人生\" # @param {type: \"string\"}\n",
        "\n",
        "# Path to the output file.\n",
        "output_subtitle_path = f\"./output-{suffix}.srt\"\n",
        "\n",
        "# Path of the output raw text file from the SRT file.\n",
        "output_raw_text_path = f\"./output-{suffix}.txt\"\n",
        "\n",
        "# Path to the directory where the model and dataset will be cached.\n",
        "cache_dir = \"./\"\n",
        "\n",
        "# The language of the lecture video.\n",
        "# @markdown **language**: The language of the lecture video.\n",
        "language = \"zh\" # @param {type:\"string\"}\n",
        "\n",
        "# Optional text to provide as a prompt for the first window.\n",
        "# @markdown **initial_prompt**: Optional text to provide as a prompt for the first window.\n",
        "initial_prompt = \"請用繁體中文\" #@param {type:\"string\"}\n",
        "\n",
        "# The temperature for sampling from the model. Higher values mean more randomness.\n",
        "# @markdown  **temperature**: The temperature for sampling from the model. Higher values mean more randomness.\n",
        "temperature = 0 # @param {type:\"slider\", min:0, max:1, step:0.1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TBhoPRKR9S4w"
      },
      "outputs": [],
      "source": [
        "# Construct DecodingOptions\n",
        "decode_options = {\n",
        "    \"language\": language,\n",
        "    \"initial_prompt\": initial_prompt,\n",
        "    \"temperature\": temperature\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SfQ5Xn-fjya",
        "outputId": "0bf121a1-c0a6-45f2-fc45-08820d4be8b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting: (1) Model: whisper-medium (2) Language: zh (2) Initial Prompt: 請用繁體中文 (3) Temperature: 0\n",
            "Transcribe 李琳山教授 信號與人生 (2023)\n"
          ]
        }
      ],
      "source": [
        "# print message.\n",
        "message = \"Transcribe 李琳山教授 信號與人生 (2023)\"\n",
        "print(f\"Setting: (1) Model: whisper-{model_name} (2) Language: {language} (2) Initial Prompt: {initial_prompt} (3) Temperature: {temperature}\")\n",
        "print(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxgZ2DNgpGlO"
      },
      "source": [
        "The code block below takes about **90 (240)** seconds to run when using the **base (medium)** model and **a T4 GPU**, although there might be some slight variation depending on the state of Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOULGnw5RF6U",
        "outputId": "62936d14-1439-465c-8dd2-39e8355ff98c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=============== Loading Whisper-medium ===============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:26<00:00, 58.1MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Begin to utilize Whisper-medium to transcribe the audio.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 104500/104500 [02:45<00:00, 629.84frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The process of speech recognition costs 209.90535426139832 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "370it [00:00, 174664.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=============== Saving the subtitle to ./output-信號與人生.srt ===============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Running ASR.\n",
        "speech_recognition(model_name=model_name, input_audio=input_audio_array, output_subtitle_path=output_subtitle_path, decode_options=decode_options, cache_dir=cache_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgmFtnti1qhU"
      },
      "source": [
        "You can check the result of automatic speech recognition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeU54f5X1erZ",
        "outputId": "879344b0-f2f9-44d6-ae80-4a9ca3218dc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "00:00:00,000 --> 00:00:04,000\n",
            "每次說這個學問是做出來的\n",
            "\n",
            "2\n",
            "00:00:06,000 --> 00:00:08,000\n",
            "什麼意思?\n",
            "\n",
            "3\n",
            "00:00:08,000 --> 00:00:12,000\n",
            "要做才會獲得學問\n",
            "\n",
            "4\n",
            "00:00:13,000 --> 00:00:16,000\n",
            "你如果每天光是坐在那裡聽\n",
            "\n",
            "5\n",
            "00:00:17,000 --> 00:00:20,000\n",
            "學問很可能是左耳進右耳出的\n",
            "\n",
            "6\n",
            "00:00:21,000 --> 00:00:23,000\n",
            "你光是坐在那兒讀\n",
            "\n",
            "7\n",
            "00:00:23,000 --> 00:00:26,000\n",
            "學問可能從眼睛進入腦海之後就忘掉了\n",
            "\n",
            "8\n",
            "00:00:26,000 --> 00:00:29,000\n",
            "如何能夠學問在腦海裡面\n",
            "\n",
            "9\n",
            "00:00:31,000 --> 00:00:33,000\n",
            "真的變成你自己學問\n",
            "\n",
            "10\n",
            "00:00:33,000 --> 00:00:35,000\n",
            "就是要做\n",
            "\n",
            "11\n",
            "00:00:36,000 --> 00:00:39,000\n",
            "可能有很多同學有這個經驗\n",
            "\n",
            "12\n",
            "00:00:39,000 --> 00:00:41,000\n",
            "你如果去修某一門課\n",
            "\n",
            "13\n",
            "00:00:41,000 --> 00:00:44,000\n",
            "或者做某一個實驗\n",
            "\n",
            "14\n",
            "00:00:44,000 --> 00:00:47,000\n",
            "在期末就是要教一個final project\n",
            "\n",
            "15\n",
            "00:00:48,000 --> 00:00:50,000\n",
            "那個final project就是要你把\n",
            "\n",
            "16\n",
            "00:00:51,000 --> 00:00:53,000\n",
            "學到的很多東西\n",
            "\n",
            "17\n",
            "00:00:53,000 --> 00:00:56,000\n",
            "最後整合在你的final project裡面\n",
            "\n",
            "18\n",
            "00:00:56,000 --> 00:00:58,000\n",
            "最後做出來的時候\n",
            "\n",
            "19\n",
            "00:00:58,000 --> 00:01:00,000\n",
            "就是把它們都整合了\n",
            "\n",
            "20\n",
            "00:01:00,000 --> 00:01:02,000\n",
            "當你學期結束\n",
            "\n",
            "21\n",
            "00:01:02,000 --> 00:01:04,000\n",
            "真的把final project做完的時候\n",
            "\n",
            "22\n",
            "00:01:04,000 --> 00:01:05,000\n",
            "你會忽然發現\n",
            "\n",
            "23\n",
            "00:01:05,000 --> 00:01:07,000\n",
            "我真的學到很多東西\n",
            "\n",
            "24\n",
            "00:01:07,000 --> 00:01:10,000\n",
            "那就是做出來的學問\n",
            "\n",
            "25\n",
            "00:01:10,000 --> 00:01:13,000\n",
            "也許可以舉另外一個例子\n",
            "\n",
            "26\n",
            "00:01:13,000 --> 00:01:16,000\n",
            "就是你如果學了某一些很複雜的演算法\n",
            "\n",
            "27\n",
            "00:01:16,000 --> 00:01:17,000\n",
            "或者什麼\n",
            "\n",
            "28\n",
            "00:01:17,000 --> 00:01:21,000\n",
            "好像覺得那些不見得在你的腦海裡\n",
            "\n",
            "29\n",
            "00:01:21,000 --> 00:01:24,000\n",
            "可是後來老師出了個習題\n",
            "\n",
            "30\n",
            "00:01:24,000 --> 00:01:26,000\n",
            "那個習題教你寫一個很大的程式\n",
            "\n",
            "31\n",
            "00:01:26,000 --> 00:01:28,000\n",
            "要把所有東西都包進去\n",
            "\n",
            "32\n",
            "00:01:28,000 --> 00:01:31,000\n",
            "當你把這個程式寫完的時候你會發現\n",
            "\n",
            "33\n",
            "00:01:31,000 --> 00:01:35,000\n",
            "你忽然把演算法裡所有東西都弄通了\n",
            "\n",
            "34\n",
            "00:01:35,000 --> 00:01:38,000\n",
            "那就是學問是做出來的\n",
            "\n",
            "35\n",
            "00:01:38,000 --> 00:01:40,000\n",
            "所以我們永遠要記得\n",
            "\n",
            "36\n",
            "00:01:40,000 --> 00:01:44,000\n",
            "盡量多動手多做\n",
            "\n",
            "37\n",
            "00:01:44,000 --> 00:01:46,000\n",
            "在動手跟做的過程之中\n",
            "\n",
            "38\n",
            "00:01:46,000 --> 00:01:49,000\n",
            "學問才可以變成是自己的\n",
            "\n",
            "39\n",
            "00:01:49,000 --> 00:01:51,000\n",
            "同樣的情形就是說\n",
            "\n",
            "40\n",
            "00:01:51,000 --> 00:01:57,000\n",
            "很多時候這樣動手或者做的表現或者成績\n",
            "\n",
            "41\n",
            "00:01:57,000 --> 00:02:00,000\n",
            "沒有一個成績單上的數字\n",
            "\n",
            "42\n",
            "00:02:00,000 --> 00:02:03,000\n",
            "使得很多人覺得那不重要\n",
            "\n",
            "43\n",
            "00:02:03,000 --> 00:02:07,000\n",
            "很多人甚至覺得這門課要做final project\n",
            "\n",
            "44\n",
            "00:02:07,000 --> 00:02:09,000\n",
            "我就不修了太累了\n",
            "\n",
            "45\n",
            "00:02:09,000 --> 00:02:12,000\n",
            "或者說那門課需要怎麼樣怎麼樣太累\n",
            "\n",
            "46\n",
            "00:02:12,000 --> 00:02:13,000\n",
            "我就不要做了\n",
            "\n",
            "47\n",
            "00:02:13,000 --> 00:02:17,000\n",
            "而不知道其實那個才是讓你做的機會\n",
            "\n",
            "48\n",
            "00:02:17,000 --> 00:02:19,000\n",
            "然後可以學到最多\n",
            "\n",
            "49\n",
            "00:02:19,000 --> 00:02:24,000\n",
            "也就是說雖然很可能那麼辛苦的做很多事\n",
            "\n",
            "50\n",
            "00:02:24,000 --> 00:02:27,000\n",
            "沒有讓你獲得什麼具體成績\n",
            "\n",
            "51\n",
            "00:02:27,000 --> 00:02:30,000\n",
            "對你的overfitting可能沒有幫助\n",
            "\n",
            "52\n",
            "00:02:30,000 --> 00:02:33,000\n",
            "可是對你的全面學習是很有幫助\n",
            "\n",
            "53\n",
            "00:02:33,000 --> 00:02:35,000\n",
            "是該學的\n",
            "\n",
            "54\n",
            "00:02:35,000 --> 00:02:38,000\n",
            "那不要漏掉這些事\n",
            "\n",
            "55\n",
            "00:02:38,000 --> 00:02:41,000\n",
            "那這是我所說的\n",
            "\n",
            "56\n",
            "00:02:41,000 --> 00:02:46,000\n",
            "那這個課業內可以做的這些事\n",
            "\n",
            "57\n",
            "00:02:46,000 --> 00:02:50,000\n",
            "那剛才我們講到思考的時候\n",
            "\n",
            "58\n",
            "00:02:50,000 --> 00:02:52,000\n",
            "我覺得我漏掉一點\n",
            "\n",
            "59\n",
            "00:02:52,000 --> 00:02:56,000\n",
            "你如果修我的信號課你可能會發現\n",
            "\n",
            "60\n",
            "00:02:56,000 --> 00:03:00,000\n",
            "我上課沒講到一個數學式子的時候\n",
            "\n",
            "61\n",
            "00:03:00,000 --> 00:03:02,000\n",
            "我通常都不推他的\n",
            "\n",
            "62\n",
            "00:03:02,000 --> 00:03:06,000\n",
            "我是在解釋那個數學式子在說什麼話\n",
            "\n",
            "63\n",
            "00:03:06,000 --> 00:03:08,000\n",
            "同樣的呢\n",
            "\n",
            "64\n",
            "00:03:08,000 --> 00:03:10,000\n",
            "沒講到一個什麼什麼事情的時候\n",
            "\n",
            "65\n",
            "00:03:10,000 --> 00:03:14,000\n",
            "我通常就在解釋他在說什麼話\n",
            "\n",
            "66\n",
            "00:03:14,000 --> 00:03:16,000\n",
            "也就是說\n",
            "\n",
            "67\n",
            "00:03:16,000 --> 00:03:20,000\n",
            "我在講的就是我讀到特本那裡的時候\n",
            "\n",
            "68\n",
            "00:03:20,000 --> 00:03:22,000\n",
            "我心裡怎麼想的\n",
            "\n",
            "69\n",
            "00:03:22,000 --> 00:03:28,000\n",
            "也就是我在告訴同學如何這個讀書的時候\n",
            "\n",
            "70\n",
            "00:03:28,000 --> 00:03:32,000\n",
            "如何一面讀一面練習思考\n",
            "\n",
            "71\n",
            "00:03:32,000 --> 00:03:37,000\n",
            "那這個才是最重要的一件事\n",
            "\n",
            "72\n",
            "00:03:37,000 --> 00:03:40,000\n",
            "如何培養自己思考的能力\n",
            "\n",
            "73\n",
            "00:03:40,000 --> 00:03:42,000\n",
            "跟培養思考的習慣\n",
            "\n",
            "74\n",
            "00:03:42,000 --> 00:03:46,000\n",
            "我覺得最好的辦法就是讀書的時候\n",
            "\n",
            "75\n",
            "00:03:46,000 --> 00:03:50,000\n",
            "凡是讀到一個數學式子都去想一想\n",
            "\n",
            "76\n",
            "00:03:50,000 --> 00:03:53,000\n",
            "那個數學式子到底在說什麼\n",
            "\n",
            "77\n",
            "00:03:53,000 --> 00:03:57,000\n",
            "凡是讀到特本上講什麼就去想一想\n",
            "\n",
            "78\n",
            "00:03:57,000 --> 00:03:59,000\n",
            "那個到底在說什麼\n",
            "\n",
            "79\n",
            "00:03:59,000 --> 00:04:03,000\n",
            "你要真的了解他在說什麼的時候\n",
            "\n",
            "80\n",
            "00:04:03,000 --> 00:04:06,000\n",
            "你就用了很多思考的功夫\n",
            "\n",
            "81\n",
            "00:04:06,000 --> 00:04:09,000\n",
            "你就在練習自己思考的能力了\n",
            "\n",
            "82\n",
            "00:04:09,000 --> 00:04:14,000\n",
            "好 以上說的是課業內的部分\n",
            "\n",
            "83\n",
            "00:04:14,000 --> 00:04:18,000\n",
            "那當然除了課業內之外呢\n",
            "\n",
            "84\n",
            "00:04:18,000 --> 00:04:21,000\n",
            "還有一大堆是不在課業內的\n",
            "\n",
            "85\n",
            "00:04:21,000 --> 00:04:24,000\n",
            "那就是課業外的\n",
            "\n",
            "86\n",
            "00:04:24,000 --> 00:04:27,000\n",
            "課業外也有很多式的\n",
            "\n",
            "87\n",
            "00:04:27,000 --> 00:04:33,000\n",
            "那我們可以舉例來說\n",
            "\n",
            "88\n",
            "00:04:33,000 --> 00:04:38,000\n",
            "課業外有什麼可以學習的\n",
            "\n",
            "89\n",
            "00:04:38,000 --> 00:04:42,000\n",
            "那我通常把學習定義成為\n",
            "\n",
            "90\n",
            "00:04:42,000 --> 00:04:43,000\n",
            "什麼是學習\n",
            "\n",
            "91\n",
            "00:04:43,000 --> 00:04:49,000\n",
            "學習就是一種增長\n",
            "\n",
            "92\n",
            "00:04:49,000 --> 00:04:53,000\n",
            "一種進步\n",
            "\n",
            "93\n",
            "00:04:53,000 --> 00:04:57,000\n",
            "然後獲得快樂\n",
            "\n",
            "94\n",
            "00:04:57,000 --> 00:05:00,000\n",
            "這就是學習\n",
            "\n",
            "95\n",
            "00:05:00,000 --> 00:05:03,000\n",
            "所以即使是課業外的任何事情\n",
            "\n",
            "96\n",
            "00:05:03,000 --> 00:05:05,000\n",
            "只要你覺得是有增長的\n",
            "\n",
            "97\n",
            "00:05:05,000 --> 00:05:07,000\n",
            "是有進步的\n",
            "\n",
            "98\n",
            "00:05:07,000 --> 00:05:08,000\n",
            "讓你覺得快樂的\n",
            "\n",
            "99\n",
            "00:05:08,000 --> 00:05:12,000\n",
            "那應該就是值得學習的地方\n",
            "\n",
            "100\n",
            "00:05:12,000 --> 00:05:16,000\n",
            "那我們可以舉很多例子\n",
            "\n",
            "101\n",
            "00:05:16,000 --> 00:05:20,000\n",
            "譬如說很多同學喜歡打球\n",
            "\n",
            "102\n",
            "00:05:20,000 --> 00:05:22,000\n",
            "打球是不是學習\n",
            "\n",
            "103\n",
            "00:05:22,000 --> 00:05:24,000\n",
            "當然是\n",
            "\n",
            "104\n",
            "00:05:24,000 --> 00:05:26,000\n",
            "在打球中間有沒有增長\n",
            "\n",
            "105\n",
            "00:05:26,000 --> 00:05:27,000\n",
            "當然是\n",
            "\n",
            "106\n",
            "00:05:27,000 --> 00:05:30,000\n",
            "在打球中間有沒有增長\n",
            "\n",
            "107\n",
            "00:05:30,000 --> 00:05:31,000\n",
            "當然有增長\n",
            "\n",
            "108\n",
            "00:05:31,000 --> 00:05:35,000\n",
            "打球不只是對健康有增長\n",
            "\n",
            "109\n",
            "00:05:35,000 --> 00:05:39,000\n",
            "而且可能對於譬如說手腦協調\n",
            "\n",
            "110\n",
            "00:05:39,000 --> 00:05:41,000\n",
            "譬如說團隊精神\n",
            "\n",
            "111\n",
            "00:05:41,000 --> 00:05:44,000\n",
            "譬如說個人之間的互動\n",
            "\n",
            "112\n",
            "00:05:44,000 --> 00:05:45,000\n",
            "什麼可能都有幫助\n",
            "\n",
            "113\n",
            "00:05:45,000 --> 00:05:47,000\n",
            "所以打球當然是有增長的\n",
            "\n",
            "114\n",
            "00:05:47,000 --> 00:05:50,000\n",
            "那當然是很好的學習的機會\n",
            "\n",
            "115\n",
            "00:05:50,000 --> 00:05:52,000\n",
            "有人喜歡爬山\n",
            "\n",
            "116\n",
            "00:05:52,000 --> 00:05:54,000\n",
            "爬山是不是好的學習機會\n",
            "\n",
            "117\n",
            "00:05:54,000 --> 00:05:55,000\n",
            "當然是\n",
            "\n",
            "118\n",
            "00:05:55,000 --> 00:05:57,000\n",
            "這個我以前兩年前就講過很多\n",
            "\n",
            "119\n",
            "00:05:57,000 --> 00:05:59,000\n",
            "爬山可以學到很多的\n",
            "\n",
            "120\n",
            "00:05:59,000 --> 00:06:02,000\n",
            "那爬山當然是一種學習\n",
            "\n",
            "121\n",
            "00:06:02,000 --> 00:06:03,000\n",
            "有人說我不喜歡爬山\n",
            "\n",
            "122\n",
            "00:06:03,000 --> 00:06:05,000\n",
            "我去旅行好不好\n",
            "\n",
            "123\n",
            "00:06:05,000 --> 00:06:07,000\n",
            "旅行當然好\n",
            "\n",
            "124\n",
            "00:06:07,000 --> 00:06:09,000\n",
            "旅行可以增長見識\n",
            "\n",
            "125\n",
            "00:06:09,000 --> 00:06:11,000\n",
            "可以擴增事業\n",
            "\n",
            "126\n",
            "00:06:11,000 --> 00:06:13,000\n",
            "可以增加很多很多\n",
            "\n",
            "127\n",
            "00:06:13,000 --> 00:06:14,000\n",
            "當然是有進步的\n",
            "\n",
            "128\n",
            "00:06:14,000 --> 00:06:16,000\n",
            "所以當然是很好的學習\n",
            "\n",
            "129\n",
            "00:06:16,000 --> 00:06:20,000\n",
            "你凡是獲得快樂都是很好的事\n",
            "\n",
            "130\n",
            "00:06:20,000 --> 00:06:23,000\n",
            "那這些都值得下功夫去\n",
            "\n",
            "131\n",
            "00:06:23,000 --> 00:06:25,000\n",
            "把它看成是學習\n",
            "\n",
            "132\n",
            "00:06:25,000 --> 00:06:27,000\n",
            "都值得下功夫去做的\n",
            "\n",
            "133\n",
            "00:06:27,000 --> 00:06:29,000\n",
            "我們再講另外一系列\n",
            "\n",
            "134\n",
            "00:06:29,000 --> 00:06:30,000\n",
            "譬如說\n",
            "\n",
            "135\n",
            "00:06:30,000 --> 00:06:34,000\n",
            "有人說談戀愛是不是學習\n",
            "\n",
            "136\n",
            "00:06:34,000 --> 00:06:37,000\n",
            "談戀愛除了你在談戀愛上\n",
            "\n",
            "137\n",
            "00:06:37,000 --> 00:06:39,000\n",
            "會有收穫以外\n",
            "\n",
            "138\n",
            "00:06:39,000 --> 00:06:41,000\n",
            "本身也是有收穫的\n",
            "\n",
            "139\n",
            "00:06:41,000 --> 00:06:44,000\n",
            "因為讓你體驗到人跟人之間\n",
            "\n",
            "140\n",
            "00:06:44,000 --> 00:06:45,000\n",
            "的各種感覺\n",
            "\n",
            "141\n",
            "00:06:45,000 --> 00:06:48,000\n",
            "人跟人之間的各種期待等等\n",
            "\n",
            "142\n",
            "00:06:48,000 --> 00:06:50,000\n",
            "有沒有幫助\n",
            "\n",
            "143\n",
            "00:06:50,000 --> 00:06:52,000\n",
            "當然有幫助\n",
            "\n",
            "144\n",
            "00:06:52,000 --> 00:06:54,000\n",
            "對每一個人都是很好的學習\n",
            "\n",
            "145\n",
            "00:06:54,000 --> 00:06:57,000\n",
            "所以談戀愛當然是一件很好的事\n",
            "\n",
            "146\n",
            "00:06:57,000 --> 00:07:00,000\n",
            "有人會說那要靠緣分\n",
            "\n",
            "147\n",
            "00:07:00,000 --> 00:07:02,000\n",
            "沒有緣分沒有辦法\n",
            "\n",
            "148\n",
            "00:07:02,000 --> 00:07:03,000\n",
            "對不對\n",
            "\n",
            "149\n",
            "00:07:03,000 --> 00:07:04,000\n",
            "對\n",
            "\n",
            "150\n",
            "00:07:04,000 --> 00:07:06,000\n",
            "但是你不是一定要談戀愛嗎\n",
            "\n",
            "151\n",
            "00:07:06,000 --> 00:07:07,000\n",
            "你可以交朋友\n",
            "\n",
            "152\n",
            "00:07:07,000 --> 00:07:10,000\n",
            "交朋友是不是學習\n",
            "\n",
            "153\n",
            "00:07:10,000 --> 00:07:11,000\n",
            "當然是\n",
            "\n",
            "154\n",
            "00:07:11,000 --> 00:07:13,000\n",
            "交朋友也一樣\n",
            "\n",
            "155\n",
            "00:07:13,000 --> 00:07:16,000\n",
            "讓我們學到很多人際的互動\n",
            "\n",
            "156\n",
            "00:07:16,000 --> 00:07:20,000\n",
            "學到很多人跟人之間的溝通\n",
            "\n",
            "157\n",
            "00:07:20,000 --> 00:07:22,000\n",
            "人跟人之間的期待\n",
            "\n",
            "158\n",
            "00:07:22,000 --> 00:07:24,000\n",
            "人跟人之間的感覺\n",
            "\n",
            "159\n",
            "00:07:24,000 --> 00:07:26,000\n",
            "這都是交朋友之後學到的\n",
            "\n",
            "160\n",
            "00:07:26,000 --> 00:07:28,000\n",
            "對我們電機系的同學而言\n",
            "\n",
            "161\n",
            "00:07:28,000 --> 00:07:31,000\n",
            "你四周有一大群好同學\n",
            "\n",
            "162\n",
            "00:07:31,000 --> 00:07:34,000\n",
            "都是很好的交朋友的對象\n",
            "\n",
            "163\n",
            "00:07:34,000 --> 00:07:36,000\n",
            "你下一番功夫交朋友好不好\n",
            "\n",
            "164\n",
            "00:07:36,000 --> 00:07:37,000\n",
            "好\n",
            "\n",
            "165\n",
            "00:07:37,000 --> 00:07:40,000\n",
            "當然是有幫助的\n",
            "\n",
            "166\n",
            "00:07:40,000 --> 00:07:42,000\n",
            "另外當然我們可以舉很多\n",
            "\n",
            "167\n",
            "00:07:42,000 --> 00:07:44,000\n",
            "我們最現成的例子\n",
            "\n",
            "168\n",
            "00:07:44,000 --> 00:07:47,000\n",
            "譬如說我們的戲學會辦各種活動\n",
            "\n",
            "169\n",
            "00:07:47,000 --> 00:07:49,000\n",
            "那些活動有沒有幫助\n",
            "\n",
            "170\n",
            "00:07:49,000 --> 00:07:50,000\n",
            "當然有\n",
            "\n",
            "171\n",
            "00:07:50,000 --> 00:07:54,000\n",
            "我們舉例來講電業\n",
            "\n",
            "172\n",
            "00:07:54,000 --> 00:07:57,000\n",
            "你如果去參加某一個舞跳個舞\n",
            "\n",
            "173\n",
            "00:07:57,000 --> 00:08:00,000\n",
            "或者參加某個劇演個劇\n",
            "\n",
            "174\n",
            "00:08:00,000 --> 00:08:01,000\n",
            "有沒有幫助\n",
            "\n",
            "175\n",
            "00:08:01,000 --> 00:08:02,000\n",
            "當然有幫助\n",
            "\n",
            "176\n",
            "00:08:02,000 --> 00:08:05,000\n",
            "你在這中間一定發現有所增長\n",
            "\n",
            "177\n",
            "00:08:05,000 --> 00:08:06,000\n",
            "有所進步\n",
            "\n",
            "178\n",
            "00:08:06,000 --> 00:08:09,000\n",
            "那是為什麼有那麼多同學要去參加\n",
            "\n",
            "179\n",
            "00:08:09,000 --> 00:08:13,000\n",
            "就是因為發現那個確實是有增長有進步\n",
            "\n",
            "180\n",
            "00:08:13,000 --> 00:08:15,000\n",
            "有的人說\n",
            "\n",
            "181\n",
            "00:08:15,000 --> 00:08:17,000\n",
            "我不去跳那個舞\n",
            "\n",
            "182\n",
            "00:08:17,000 --> 00:08:20,000\n",
            "或者演那個劇\n",
            "\n",
            "183\n",
            "00:08:20,000 --> 00:08:22,000\n",
            "我做幕後的\n",
            "\n",
            "184\n",
            "00:08:22,000 --> 00:08:25,000\n",
            "譬如說是幕後的什麼規劃\n",
            "\n",
            "185\n",
            "00:08:25,000 --> 00:08:29,000\n",
            "或者說是什麼光舞的什麼軟體組\n",
            "\n",
            "186\n",
            "00:08:29,000 --> 00:08:32,000\n",
            "還是什麼服裝道具組\n",
            "\n",
            "187\n",
            "00:08:32,000 --> 00:08:33,000\n",
            "一樣\n",
            "\n",
            "188\n",
            "00:08:33,000 --> 00:08:36,000\n",
            "那個都是可以有獲得很多的增長\n",
            "\n",
            "189\n",
            "00:08:36,000 --> 00:08:37,000\n",
            "很多進步的\n",
            "\n",
            "190\n",
            "00:08:37,000 --> 00:08:39,000\n",
            "當然都是很有用的\n",
            "\n",
            "191\n",
            "00:08:39,000 --> 00:08:42,000\n",
            "都是很好的學習\n",
            "\n",
            "192\n",
            "00:08:42,000 --> 00:08:47,000\n",
            "那當然也包括電業以外的戲學會\n",
            "\n",
            "193\n",
            "00:08:47,000 --> 00:08:50,000\n",
            "其他的各種活動都一樣\n",
            "\n",
            "194\n",
            "00:08:50,000 --> 00:08:55,000\n",
            "也包括電機系以外的其他的校內\n",
            "\n",
            "195\n",
            "00:08:55,000 --> 00:08:59,000\n",
            "或者校外的各種活動幾乎都一樣\n",
            "\n",
            "196\n",
            "00:08:59,000 --> 00:09:02,000\n",
            "都可以讓人有所增長有所進步\n",
            "\n",
            "197\n",
            "00:09:02,000 --> 00:09:04,000\n",
            "都是很好的學習的機會\n",
            "\n",
            "198\n",
            "00:09:04,000 --> 00:09:06,000\n",
            "都是很好的學習\n",
            "\n",
            "199\n",
            "00:09:06,000 --> 00:09:10,000\n",
            "同樣的問題是這些東西都沒有考試\n",
            "\n",
            "200\n",
            "00:09:10,000 --> 00:09:12,000\n",
            "沒有成績\n",
            "\n",
            "201\n",
            "00:09:12,000 --> 00:09:14,000\n",
            "不能顯示在成績單上\n",
            "\n",
            "202\n",
            "00:09:14,000 --> 00:09:18,000\n",
            "因此對有一些同學會認為那個浪費時間\n",
            "\n",
            "203\n",
            "00:09:18,000 --> 00:09:20,000\n",
            "我不需要花時間去做那個\n",
            "\n",
            "204\n",
            "00:09:20,000 --> 00:09:24,000\n",
            "因為不影響我的overfitting的目標\n",
            "\n",
            "205\n",
            "00:09:24,000 --> 00:09:26,000\n",
            "裡面沒有這個嘛\n",
            "\n",
            "206\n",
            "00:09:26,000 --> 00:09:28,000\n",
            "具體成績沒有這些嘛\n",
            "\n",
            "207\n",
            "00:09:28,000 --> 00:09:30,000\n",
            "那不要這樣想\n",
            "\n",
            "208\n",
            "00:09:30,000 --> 00:09:33,000\n",
            "因為那些都非常的重要\n",
            "\n",
            "209\n",
            "00:09:33,000 --> 00:09:36,000\n",
            "都對你發展非常的重要\n",
            "\n",
            "210\n",
            "00:09:36,000 --> 00:09:39,000\n",
            "那我們說電機工程\n",
            "\n",
            "211\n",
            "00:09:39,000 --> 00:09:41,000\n",
            "今天的電機工程\n",
            "\n",
            "212\n",
            "00:09:41,000 --> 00:09:44,000\n",
            "很少什麼事情自己一個人可以做成功的\n",
            "\n",
            "213\n",
            "00:09:44,000 --> 00:09:47,000\n",
            "你必須跟很多人一起\n",
            "\n",
            "214\n",
            "00:09:47,000 --> 00:09:50,000\n",
            "才可能做成功一個非常重要的\n",
            "\n",
            "215\n",
            "00:09:50,000 --> 00:09:52,000\n",
            "有意義的工作\n",
            "\n",
            "216\n",
            "00:09:52,000 --> 00:09:55,000\n",
            "那當你跟一群人在一起做的時候\n",
            "\n",
            "217\n",
            "00:09:55,000 --> 00:09:59,000\n",
            "你必須學會如何進入一個團隊\n",
            "\n",
            "218\n",
            "00:09:59,000 --> 00:10:03,000\n",
            "從邊緣開始慢慢進入核心\n",
            "\n",
            "219\n",
            "00:10:03,000 --> 00:10:06,000\n",
            "從底層開始慢慢變成leader\n",
            "\n",
            "220\n",
            "00:10:06,000 --> 00:10:09,000\n",
            "然後如何可以推動你想做的事\n",
            "\n",
            "221\n",
            "00:10:09,000 --> 00:10:13,000\n",
            "如何變成可以做到你想做的事等等\n",
            "\n",
            "222\n",
            "00:10:13,000 --> 00:10:15,000\n",
            "這些都是很重要的\n",
            "\n",
            "223\n",
            "00:10:15,000 --> 00:10:18,000\n",
            "那我們通常稱這些東西\n",
            "\n",
            "224\n",
            "00:10:18,000 --> 00:10:21,000\n",
            "是所謂的soft skills\n",
            "\n",
            "225\n",
            "00:10:21,000 --> 00:10:24,000\n",
            "也就是軟實力\n",
            "\n",
            "226\n",
            "00:10:24,000 --> 00:10:30,000\n",
            "所謂軟實力就是硬實力以外的軟實力\n",
            "\n",
            "227\n",
            "00:10:30,000 --> 00:10:34,000\n",
            "硬實力是說你電子學的功力\n",
            "\n",
            "228\n",
            "00:10:34,000 --> 00:10:36,000\n",
            "數學的功力\n",
            "\n",
            "229\n",
            "00:10:36,000 --> 00:10:40,000\n",
            "這個城市能力這種是硬實力\n",
            "\n",
            "230\n",
            "00:10:40,000 --> 00:10:45,000\n",
            "軟實力我們主要就是講各種人際之間的\n",
            "\n",
            "231\n",
            "00:10:45,000 --> 00:10:49,000\n",
            "在人跟人之間的各種能力\n",
            "\n",
            "232\n",
            "00:10:49,000 --> 00:10:54,000\n",
            "包括溝通能力協調能力交朋友的能力\n",
            "\n",
            "233\n",
            "00:10:54,000 --> 00:10:59,000\n",
            "說服人的能力團隊精神領導能力等等\n",
            "\n",
            "234\n",
            "00:10:59,000 --> 00:11:02,000\n",
            "那些就是所謂的soft skills\n",
            "\n",
            "235\n",
            "00:11:02,000 --> 00:11:04,000\n",
            "重要不重要重要\n",
            "\n",
            "236\n",
            "00:11:04,000 --> 00:11:07,000\n",
            "你看到任何一個成功的電機工程師\n",
            "\n",
            "237\n",
            "00:11:07,000 --> 00:11:09,000\n",
            "他都有一堆這種\n",
            "\n",
            "238\n",
            "00:11:09,000 --> 00:11:13,000\n",
            "這個才是他成功的一個非常重要的關鍵\n",
            "\n",
            "239\n",
            "00:11:13,000 --> 00:11:15,000\n",
            "這種東西怎麼來\n",
            "\n",
            "240\n",
            "00:11:15,000 --> 00:11:18,000\n",
            "我們剛才講的各種課業外的\n",
            "\n",
            "241\n",
            "00:11:18,000 --> 00:11:20,000\n",
            "各種學習增長的機會\n",
            "\n",
            "242\n",
            "00:11:20,000 --> 00:11:26,000\n",
            "都可以幫助一個人塑造他的soft skills\n",
            "\n",
            "243\n",
            "00:11:26,000 --> 00:11:30,000\n",
            "是有少數人的這些soft skills是天生的\n",
            "\n",
            "244\n",
            "00:11:30,000 --> 00:11:31,000\n",
            "他天生就厲害\n",
            "\n",
            "245\n",
            "00:11:31,000 --> 00:11:32,000\n",
            "有沒有\n",
            "\n",
            "246\n",
            "00:11:32,000 --> 00:11:33,000\n",
            "有\n",
            "\n",
            "247\n",
            "00:11:33,000 --> 00:11:35,000\n",
            "但這種人畢竟沒那麼多\n",
            "\n",
            "248\n",
            "00:11:35,000 --> 00:11:37,000\n",
            "對很多人而言\n",
            "\n",
            "249\n",
            "00:11:37,000 --> 00:11:42,000\n",
            "他的soft skills是自己努力慢慢培養起來的\n",
            "\n",
            "250\n",
            "00:11:42,000 --> 00:11:45,000\n",
            "我剛才一開始前面講的那一段\n",
            "\n",
            "251\n",
            "00:11:45,000 --> 00:11:49,000\n",
            "我說我在進台大電機系以前\n",
            "\n",
            "252\n",
            "00:11:49,000 --> 00:11:51,000\n",
            "我幾乎不會交朋友\n",
            "\n",
            "253\n",
            "00:11:51,000 --> 00:11:53,000\n",
            "我不太會說話\n",
            "\n",
            "254\n",
            "00:11:53,000 --> 00:11:57,000\n",
            "我在讀大學的四年裡面改變我自己\n",
            "\n",
            "255\n",
            "00:11:57,000 --> 00:12:02,000\n",
            "讓我變成有很多這方面的能力的人\n",
            "\n",
            "256\n",
            "00:12:02,000 --> 00:12:06,000\n",
            "其實最重要就是我的很多soft skills\n",
            "\n",
            "257\n",
            "00:12:06,000 --> 00:12:07,000\n",
            "都是我自己培養\n",
            "\n",
            "258\n",
            "00:12:07,000 --> 00:12:10,000\n",
            "在讀台大電機系的四年裡面\n",
            "\n",
            "259\n",
            "00:12:10,000 --> 00:12:14,000\n",
            "獲得的非常多這方面的收穫的\n",
            "\n",
            "260\n",
            "00:12:14,000 --> 00:12:18,000\n",
            "那是為什麼我每次都要強調\n",
            "\n",
            "261\n",
            "00:12:18,000 --> 00:12:21,000\n",
            "這個東西有多麼重要\n",
            "\n",
            "262\n",
            "00:12:21,000 --> 00:12:27,000\n",
            "我之前曾經在幾年前的這個\n",
            "\n",
            "263\n",
            "00:12:27,000 --> 00:12:31,000\n",
            "信號與人生裡面有說到這一件事\n",
            "\n",
            "264\n",
            "00:12:31,000 --> 00:12:33,000\n",
            "我現在不要重複\n",
            "\n",
            "265\n",
            "00:12:33,000 --> 00:12:36,000\n",
            "但是我簡單的summarize\n",
            "\n",
            "266\n",
            "00:12:36,000 --> 00:12:42,000\n",
            "我說我們電機系的電機工程師的\n",
            "\n",
            "267\n",
            "00:12:42,000 --> 00:12:45,000\n",
            "一生career的發展\n",
            "\n",
            "268\n",
            "00:12:45,000 --> 00:12:48,000\n",
            "黃金實在是在什麼時候\n",
            "\n",
            "269\n",
            "00:12:48,000 --> 00:12:52,000\n",
            "我認為是在35歲到55歲\n",
            "\n",
            "270\n",
            "00:12:52,000 --> 00:12:56,000\n",
            "這20年是我們的黃金時代\n",
            "\n",
            "271\n",
            "00:12:56,000 --> 00:12:58,000\n",
            "在這以前當然更好\n",
            "\n",
            "272\n",
            "00:12:58,000 --> 00:13:01,000\n",
            "只是說可能各方面尚未具備\n",
            "\n",
            "273\n",
            "00:13:01,000 --> 00:13:03,000\n",
            "還沒有完全訓練的好\n",
            "\n",
            "274\n",
            "00:13:03,000 --> 00:13:05,000\n",
            "在這以後是最好的\n",
            "\n",
            "275\n",
            "00:13:05,000 --> 00:13:10,000\n",
            "這以後年紀大了難免有一些要打個折扣等等\n",
            "\n",
            "276\n",
            "00:13:10,000 --> 00:13:13,000\n",
            "就這裡面我們看到\n",
            "\n",
            "277\n",
            "00:13:13,000 --> 00:13:15,000\n",
            "我們的電機系的畢業的同學\n",
            "\n",
            "278\n",
            "00:13:15,000 --> 00:13:18,000\n",
            "過去有幾千人畢業我都看到\n",
            "\n",
            "279\n",
            "00:13:18,000 --> 00:13:22,000\n",
            "我覺得有的人的發展是像這樣\n",
            "\n",
            "280\n",
            "00:13:22,000 --> 00:13:24,000\n",
            "有一定的斜率\n",
            "\n",
            "281\n",
            "00:13:24,000 --> 00:13:28,000\n",
            "但到某一個階段它會慢慢saturate\n",
            "\n",
            "282\n",
            "00:13:28,000 --> 00:13:31,000\n",
            "有的人也許開始向上比較晚\n",
            "\n",
            "283\n",
            "00:13:31,000 --> 00:13:33,000\n",
            "但它斜率比較高\n",
            "\n",
            "284\n",
            "00:13:33,000 --> 00:13:38,000\n",
            "它最後會saturate在比較高的地方\n",
            "\n",
            "285\n",
            "00:13:38,000 --> 00:13:41,000\n",
            "也有的人也許開始的比較快\n",
            "\n",
            "286\n",
            "00:13:41,000 --> 00:13:44,000\n",
            "但是後來會overshoot之後\n",
            "\n",
            "287\n",
            "00:13:44,000 --> 00:13:46,000\n",
            "會開始收斂在比較低的地方等等\n",
            "\n",
            "288\n",
            "00:13:46,000 --> 00:13:48,000\n",
            "每一個人都不一樣\n",
            "\n",
            "289\n",
            "00:13:48,000 --> 00:13:50,000\n",
            "但是當然也有一種人\n",
            "\n",
            "290\n",
            "00:13:50,000 --> 00:13:54,000\n",
            "你會看到他一直向上走\n",
            "\n",
            "291\n",
            "00:13:54,000 --> 00:13:58,000\n",
            "完全沒有saturate\n",
            "\n",
            "292\n",
            "00:13:58,000 --> 00:14:01,000\n",
            "這些人這些差別在哪裡\n",
            "\n",
            "293\n",
            "00:14:01,000 --> 00:14:04,000\n",
            "這些東西差別在哪裡\n",
            "\n",
            "294\n",
            "00:14:04,000 --> 00:14:06,000\n",
            "我以前已經說過這件事\n",
            "\n",
            "295\n",
            "00:14:06,000 --> 00:14:08,000\n",
            "我不要多重複\n",
            "\n",
            "296\n",
            "00:14:08,000 --> 00:14:11,000\n",
            "我說最主要因素有四個\n",
            "\n",
            "297\n",
            "00:14:11,000 --> 00:14:18,000\n",
            "實力、努力、大智\n",
            "\n",
            "298\n",
            "00:14:18,000 --> 00:14:23,000\n",
            "跟self skill這四件事情\n",
            "\n",
            "299\n",
            "00:14:23,000 --> 00:14:29,000\n",
            "我認為真正影響這個的\n",
            "\n",
            "300\n",
            "00:14:29,000 --> 00:14:32,000\n",
            "不是因為電子學考得好不好\n",
            "\n",
            "301\n",
            "00:14:32,000 --> 00:14:35,000\n",
            "不是因為信號與系統念得好不好\n",
            "\n",
            "302\n",
            "00:14:35,000 --> 00:14:37,000\n",
            "也就是我剛才講\n",
            "\n",
            "303\n",
            "00:14:37,000 --> 00:14:39,000\n",
            "你把每一門必修課\n",
            "\n",
            "304\n",
            "00:14:39,000 --> 00:14:41,000\n",
            "當成是單一跑道\n",
            "\n",
            "305\n",
            "00:14:41,000 --> 00:14:43,000\n",
            "跑到第一名並不表示怎樣\n",
            "\n",
            "306\n",
            "00:14:43,000 --> 00:14:45,000\n",
            "我們最後不看那個的\n",
            "\n",
            "307\n",
            "00:14:45,000 --> 00:14:47,000\n",
            "最後看的是這個\n",
            "\n",
            "308\n",
            "00:14:47,000 --> 00:14:49,000\n",
            "這個是怎麼樣影響\n",
            "\n",
            "309\n",
            "00:14:49,000 --> 00:14:51,000\n",
            "我認為是這四件事\n",
            "\n",
            "310\n",
            "00:14:51,000 --> 00:14:55,000\n",
            "就是實力、努力、大智跟self skills\n",
            "\n",
            "311\n",
            "00:14:55,000 --> 00:14:57,000\n",
            "這四件事裡面\n",
            "\n",
            "312\n",
            "00:14:57,000 --> 00:14:59,000\n",
            "我們現在可以summarize\n",
            "\n",
            "313\n",
            "00:14:59,000 --> 00:15:00,000\n",
            "我剛才講的\n",
            "\n",
            "314\n",
            "00:15:00,000 --> 00:15:02,000\n",
            "什麼是實力\n",
            "\n",
            "315\n",
            "00:15:02,000 --> 00:15:05,000\n",
            "實力就是所有的這些\n",
            "\n",
            "316\n",
            "00:15:05,000 --> 00:15:07,000\n",
            "我們電機工程的專業領域裡面\n",
            "\n",
            "317\n",
            "00:15:07,000 --> 00:15:09,000\n",
            "各種東西的實力\n",
            "\n",
            "318\n",
            "00:15:09,000 --> 00:15:11,000\n",
            "實力怎麼厲害法\n",
            "\n",
            "319\n",
            "00:15:11,000 --> 00:15:13,000\n",
            "就是我剛才講的\n",
            "\n",
            "320\n",
            "00:15:13,000 --> 00:15:16,000\n",
            "你如果都是在做全面的學習的話\n",
            "\n",
            "321\n",
            "00:15:16,000 --> 00:15:18,000\n",
            "你就會學到各種該學到的\n",
            "\n",
            "322\n",
            "00:15:18,000 --> 00:15:20,000\n",
            "最後你的實力就是很強的\n",
            "\n",
            "323\n",
            "00:15:20,000 --> 00:15:25,000\n",
            "所以實力最主要就是不要overfitting\n",
            "\n",
            "324\n",
            "00:15:25,000 --> 00:15:27,000\n",
            "要盡量都做\n",
            "\n",
            "325\n",
            "00:15:27,000 --> 00:15:31,000\n",
            "學到該學的全面的學習\n",
            "\n",
            "326\n",
            "00:15:31,000 --> 00:15:33,000\n",
            "努力是沒有疑問\n",
            "\n",
            "327\n",
            "00:15:33,000 --> 00:15:34,000\n",
            "每一個人都了解\n",
            "\n",
            "328\n",
            "00:15:34,000 --> 00:15:36,000\n",
            "確實我們可以看到\n",
            "\n",
            "329\n",
            "00:15:36,000 --> 00:15:38,000\n",
            "一個人在未來的幾十年裡面\n",
            "\n",
            "330\n",
            "00:15:38,000 --> 00:15:40,000\n",
            "有的人他一直努力\n",
            "\n",
            "331\n",
            "00:15:40,000 --> 00:15:42,000\n",
            "有的人慢慢不太努力等等\n",
            "\n",
            "332\n",
            "00:15:42,000 --> 00:15:44,000\n",
            "這個是有明顯差別的\n",
            "\n",
            "333\n",
            "00:15:44,000 --> 00:15:46,000\n",
            "那self skills我剛才已經講了\n",
            "\n",
            "334\n",
            "00:15:46,000 --> 00:15:50,000\n",
            "就是很多我們平常沒有算成績\n",
            "\n",
            "335\n",
            "00:15:50,000 --> 00:15:52,000\n",
            "覺得大家不重視的事情\n",
            "\n",
            "336\n",
            "00:15:52,000 --> 00:15:54,000\n",
            "其實它常常是很重要的\n",
            "\n",
            "337\n",
            "00:15:54,000 --> 00:15:56,000\n",
            "你如果好好的\n",
            "\n",
            "338\n",
            "00:15:56,000 --> 00:16:00,000\n",
            "多在各種課業外的事情上\n",
            "\n",
            "339\n",
            "00:16:00,000 --> 00:16:02,000\n",
            "增長進步的話\n",
            "\n",
            "340\n",
            "00:16:02,000 --> 00:16:04,000\n",
            "你這些東西會很強\n",
            "\n",
            "341\n",
            "00:16:04,000 --> 00:16:06,000\n",
            "你會很厲害的\n",
            "\n",
            "342\n",
            "00:16:06,000 --> 00:16:08,000\n",
            "當然對少數人而言\n",
            "\n",
            "343\n",
            "00:16:08,000 --> 00:16:09,000\n",
            "他天生就有\n",
            "\n",
            "344\n",
            "00:16:09,000 --> 00:16:10,000\n",
            "他可能不需要\n",
            "\n",
            "345\n",
            "00:16:10,000 --> 00:16:12,000\n",
            "這是每一個人不一樣的\n",
            "\n",
            "346\n",
            "00:16:12,000 --> 00:16:14,000\n",
            "那這三個我都提過了\n",
            "\n",
            "347\n",
            "00:16:14,000 --> 00:16:16,000\n",
            "那麼大致我還沒有提\n",
            "\n",
            "348\n",
            "00:16:16,000 --> 00:16:18,000\n",
            "其實大致沒有什麼要特別說的\n",
            "\n",
            "349\n",
            "00:16:18,000 --> 00:16:21,000\n",
            "那應該就是我剛才前面有講過\n",
            "\n",
            "350\n",
            "00:16:21,000 --> 00:16:26,000\n",
            "就是每一個人可以有你自己的長程目標\n",
            "\n",
            "351\n",
            "00:16:26,000 --> 00:16:29,000\n",
            "那有的人本來就有了\n",
            "\n",
            "352\n",
            "00:16:29,000 --> 00:16:32,000\n",
            "有的人也許我平常沒有想過\n",
            "\n",
            "353\n",
            "00:16:32,000 --> 00:16:37,000\n",
            "那你可以在適當時機開始想\n",
            "\n",
            "354\n",
            "00:16:37,000 --> 00:16:40,000\n",
            "我有沒有想要做什麼事情\n",
            "\n",
            "355\n",
            "00:16:40,000 --> 00:16:43,000\n",
            "哪些事情可能是我的長程目標\n",
            "\n",
            "356\n",
            "00:16:43,000 --> 00:16:48,000\n",
            "我希望最後讓我花個5年10年\n",
            "\n",
            "357\n",
            "00:16:48,000 --> 00:16:50,000\n",
            "15年或者更長\n",
            "\n",
            "358\n",
            "00:16:50,000 --> 00:16:52,000\n",
            "我把我的很多的努力\n",
            "\n",
            "359\n",
            "00:16:52,000 --> 00:16:55,000\n",
            "都來把某一些事情做得非常漂亮\n",
            "\n",
            "360\n",
            "00:16:55,000 --> 00:16:57,000\n",
            "那是我很想做的事\n",
            "\n",
            "361\n",
            "00:16:57,000 --> 00:17:00,000\n",
            "那就是長程目標\n",
            "\n",
            "362\n",
            "00:17:00,000 --> 00:17:04,000\n",
            "如果我覺得做那些事情會讓我非常的\n",
            "\n",
            "363\n",
            "00:17:04,000 --> 00:17:05,000\n",
            "覺得有意義\n",
            "\n",
            "364\n",
            "00:17:05,000 --> 00:17:07,000\n",
            "願意花功夫下去做的\n",
            "\n",
            "365\n",
            "00:17:07,000 --> 00:17:09,000\n",
            "那就是我的長程目標\n",
            "\n",
            "366\n",
            "00:17:09,000 --> 00:17:12,000\n",
            "那有的人如果可以想出這個來的話\n",
            "\n",
            "367\n",
            "00:17:12,000 --> 00:17:15,000\n",
            "那就是他的大致\n",
            "\n",
            "368\n",
            "00:17:15,000 --> 00:17:17,000\n",
            "那越是有這種大致的人\n",
            "\n",
            "369\n",
            "00:17:17,000 --> 00:17:20,000\n",
            "也比較容易向上衝\n",
            "\n",
            "370\n",
            "00:17:20,000 --> 00:17:25,000\n",
            "那我感覺起來真正影響的就是這四件事\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "''' Open the SRT file and read its content.\n",
        "The format of SRT is:\n",
        "\n",
        "[Index]\n",
        "[Begin time] (hour:minute:second) --> [End time] (hour:minute:second)\n",
        "[Transcription]\n",
        "\n",
        "'''\n",
        "\n",
        "with open(output_subtitle_path, 'r', encoding='utf-8') as file:\n",
        "    content = file.read()\n",
        "\n",
        "print(content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7JcN-kUDE_g"
      },
      "source": [
        "# Part3 - Preprocess the results of automatic speech recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "P2R40faVDShf"
      },
      "outputs": [],
      "source": [
        "def extract_and_save_text(srt_filename, output_filename):\n",
        "\n",
        "    '''\n",
        "    (1) Objective:\n",
        "        - This function extracts the text from an SRT file and saves it to a new text file.\n",
        "        - It also converts the Simplified Chinese to Traditional Chinese.\n",
        "\n",
        "    (2) Arguments:\n",
        "\n",
        "        - srt_filename: The path to the SRT file.\n",
        "\n",
        "        - output_filename: The name of the output text file.\n",
        "\n",
        "    (3) Example:\n",
        "        - If your SRT file is named 'subtitle.srt' and you want to save the extracted text to a file named 'output.txt', you can use the function like this:\n",
        "            extract_and_save_text('subtitle.srt', 'output.txt')\n",
        "\n",
        "    '''\n",
        "\n",
        "    # Open the SRT file and read its content.\n",
        "    with open(srt_filename, 'r', encoding='utf-8') as file:\n",
        "        content = file.read()\n",
        "\n",
        "    # Use regular expression to remove the timecode.\n",
        "    pure_text = re.sub(r'\\d+\\n\\d{2}:\\d{2}:\\d{2},\\d{3} --> \\d{2}:\\d{2}:\\d{2},\\d{3}\\n', '', content)\n",
        "\n",
        "    # Remove the empty lines.\n",
        "    pure_text = re.sub(r'\\n\\n+', '\\n', pure_text)\n",
        "\n",
        "    # Creating an instance of OpenCC for Simplified to Traditional Chinese conversion.\n",
        "    cc = OpenCC('s2t')\n",
        "    pure_text_conversion = cc.convert(pure_text)\n",
        "\n",
        "    # Write the extracted text to a new file.\n",
        "    with open(output_filename, 'w', encoding='utf-8') as output_file:\n",
        "        output_file.write(pure_text_conversion)\n",
        "\n",
        "    print(f'Extracted text has been saved to {output_filename}.\\n\\n')\n",
        "\n",
        "    return pure_text_conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tWDl1vuADd0e"
      },
      "outputs": [],
      "source": [
        "def chunk_text(text, max_length):\n",
        "    \"\"\"\n",
        "    (1) Objective:\n",
        "        - This function is used to split a long string into smaller strings of a specified length.\n",
        "\n",
        "    (2) Arguments:\n",
        "        - text: str, the long string to be split.\n",
        "        - max_length: int, the maximum length of each smaller string.\n",
        "\n",
        "    (3) Returns:\n",
        "        - split_text: list, a list of smaller strings.\n",
        "\n",
        "    (3) Example:\n",
        "        - If you want to split a string named \"long_string\" into smaller strings of length 100, you can use the function like this:\n",
        "            chunk_text(long_string, 100)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    return textwrap.wrap(text, max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aO01S41pOsSP"
      },
      "outputs": [],
      "source": [
        "''' In this block, you can modify your desired parameters and the path of input file. '''\n",
        "\n",
        "# # The length of the text chunks.\n",
        "chunk_length = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-PpbkoS-5bI",
        "outputId": "5c2c6a98-65af-4c62-b452-50096794a592"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted text has been saved to ./output-信號與人生.txt.\n",
            "\n",
            "\n",
            "Review the results of splitting the long text into several short texts.\n",
            "\n",
            "\n",
            "========== The 1-st segment of the split (505 words) ==========\n",
            "\n",
            "\n",
            "每次說這個學問是做出來的 什麼意思? 要做才會獲得學問 你如果每天光是坐在那裡聽 學問很可能是左耳進右耳出的 你光是坐在那兒讀\n",
            "\n",
            "學問可能從眼睛進入腦海之後就忘掉了 如何能夠學問在腦海裡面 真的變成你自己學問 就是要做 可能有很多同學有這個經驗 你如果去修某一門課 或者做某一個實驗\n",
            "\n",
            "在期末就是要教一個final project 那個final project就是要你把 學到的很多東西 最後整合在你的final project裡面\n",
            "\n",
            "最後做出來的時候 就是把它們都整合了 當你學期結束 真的把final project做完的時候 你會忽然發現 我真的學到很多東西 那就是做出來的學問\n",
            "\n",
            "也許可以舉另外一個例子 就是你如果學了某一些很複雜的演算法 或者什麼 好像覺得那些不見得在你的腦海裡 可是後來老師出了個習題 那個習題教你寫一個很大的程式\n",
            "\n",
            "要把所有東西都包進去 當你把這個程式寫完的時候你會發現 你忽然把演算法裡所有東西都弄通了 那就是學問是做出來的 所以我們永遠要記得 盡量多動手多做\n",
            "\n",
            "在動手跟做的過程之中 學問纔可以變成是自己的 同樣的情形就是說 很多時候這樣動手或者做的表現或者成績 沒有一個成績單上的數字\n",
            "\n",
            "\n",
            "========== The 2-nd segment of the split (506 words) ==========\n",
            "\n",
            "\n",
            "使得很多人覺得那不重要 很多人甚至覺得這門課要做final project 我就不修了太累了 或者說那門課需要怎麼樣怎麼樣太累 我就不要做了\n",
            "\n",
            "而不知道其實那個纔是讓你做的機會 然後可以學到最多 也就是說雖然很可能那麼辛苦的做很多事 沒有讓你獲得什麼具體成績 對你的overfitting可能沒有幫助\n",
            "\n",
            "可是對你的全面學習是很有幫助 是該學的 那不要漏掉這些事 那這是我所說的 那這個課業內可以做的這些事 那剛才我們講到思考的時候 我覺得我漏掉一點\n",
            "\n",
            "你如果修我的信號課你可能會發現 我上課沒講到一個數學式子的時候 我通常都不推他的 我是在解釋那個數學式子在說什麼話 同樣的呢 沒講到一個什麼什麼事情的時候\n",
            "\n",
            "我通常就在解釋他在說什麼話 也就是說 我在講的就是我讀到特本那裡的時候 我心裡怎麼想的 也就是我在告訴同學如何這個讀書的時候 如何一面讀一面練習思考\n",
            "\n",
            "那這個纔是最重要的一件事 如何培養自己思考的能力 跟培養思考的習慣 我覺得最好的辦法就是讀書的時候 凡是讀到一個數學式子都去想一想 那個數學式子到底在說什麼\n",
            "\n",
            "凡是讀到特本上講什麼就去想一想 那個到底在說什麼 你要真的瞭解他在說什麼的時候 你就用了很多思考的功夫\n",
            "\n",
            "\n",
            "========== The 3-rd segment of the split (504 words) ==========\n",
            "\n",
            "\n",
            "你就在練習自己思考的能力了 好 以上說的是課業內的部分 那當然除了課業內之外呢 還有一大堆是不在課業內的 那就是課業外的 課業外也有很多式的 那我們可以舉例來說\n",
            "\n",
            "課業外有什麼可以學習的 那我通常把學習定義成為 什麼是學習 學習就是一種增長 一種進步 然後獲得快樂 這就是學習 所以即使是課業外的任何事情\n",
            "\n",
            "只要你覺得是有增長的 是有進步的 讓你覺得快樂的 那應該就是值得學習的地方 那我們可以舉很多例子 譬如說很多同學喜歡打球 打球是不是學習 當然是\n",
            "\n",
            "在打球中間有沒有增長 當然是 在打球中間有沒有增長 當然有增長 打球不只是對健康有增長 而且可能對於譬如說手腦協調 譬如說團隊精神 譬如說個人之間的互動\n",
            "\n",
            "什麼可能都有幫助 所以打球當然是有增長的 那當然是很好的學習的機會 有人喜歡爬山 爬山是不是好的學習機會 當然是 這個我以前兩年前就講過很多 爬山可以學到很多的\n",
            "\n",
            "那爬山當然是一種學習 有人說我不喜歡爬山 我去旅行好不好 旅行當然好 旅行可以增長見識 可以擴增事業 可以增加很多很多 當然是有進步的 所以當然是很好的學習\n",
            "\n",
            "你凡是獲得快樂都是很好的事 那這些都值得下功夫去 把它看成是學習 都值得下功夫去做的\n",
            "\n",
            "\n",
            "========== The 4-th segment of the split (506 words) ==========\n",
            "\n",
            "\n",
            "我們再講另外一系列 譬如說 有人說談戀愛是不是學習 談戀愛除了你在談戀愛上 會有收穫以外 本身也是有收穫的 因為讓你體驗到人跟人之間 的各種感覺\n",
            "\n",
            "人跟人之間的各種期待等等 有沒有幫助 當然有幫助 對每一個人都是很好的學習 所以談戀愛當然是一件很好的事 有人會說那要靠緣分 沒有緣分沒有辦法 對不對 對\n",
            "\n",
            "但是你不是一定要談戀愛嗎 你可以交朋友 交朋友是不是學習 當然是 交朋友也一樣 讓我們學到很多人際的互動 學到很多人跟人之間的溝通 人跟人之間的期待\n",
            "\n",
            "人跟人之間的感覺 這都是交朋友之後學到的 對我們電機系的同學而言 你四周有一大羣好同學 都是很好的交朋友的對象 你下一番功夫交朋友好不好 好 當然是有幫助的\n",
            "\n",
            "另外當然我們可以舉很多 我們最現成的例子 譬如說我們的戲學會辦各種活動 那些活動有沒有幫助 當然有 我們舉例來講電業 你如果去參加某一個舞跳個舞\n",
            "\n",
            "或者參加某個劇演個劇 有沒有幫助 當然有幫助 你在這中間一定發現有所增長 有所進步 那是為什麼有那麼多同學要去參加 就是因為發現那個確實是有增長有進步 有的人說\n",
            "\n",
            "我不去跳那個舞 或者演那個劇 我做幕後的 譬如說是幕後的什麼規劃 或者說是什麼光舞的什麼軟體組\n",
            "\n",
            "\n",
            "========== The 5-th segment of the split (501 words) ==========\n",
            "\n",
            "\n",
            "還是什麼服裝道具組 一樣 那個都是可以有獲得很多的增長 很多進步的 當然都是很有用的 都是很好的學習 那當然也包括電業以外的戲學會 其他的各種活動都一樣\n",
            "\n",
            "也包括電機系以外的其他的校內 或者校外的各種活動幾乎都一樣 都可以讓人有所增長有所進步 都是很好的學習的機會 都是很好的學習 同樣的問題是這些東西都沒有考試\n",
            "\n",
            "沒有成績 不能顯示在成績單上 因此對有一些同學會認為那個浪費時間 我不需要花時間去做那個 因為不影響我的overfitting的目標 裡面沒有這個嘛\n",
            "\n",
            "具體成績沒有這些嘛 那不要這樣想 因為那些都非常的重要 都對你發展非常的重要 那我們說電機工程 今天的電機工程 很少什麼事情自己一個人可以做成功的\n",
            "\n",
            "你必須跟很多人一起 纔可能做成功一個非常重要的 有意義的工作 那當你跟一羣人在一起做的時候 你必須學會如何進入一個團隊 從邊緣開始慢慢進入核心\n",
            "\n",
            "從底層開始慢慢變成leader 然後如何可以推動你想做的事 如何變成可以做到你想做的事等等 這些都是很重要的 那我們通常稱這些東西 是所謂的soft\n",
            "\n",
            "skills 也就是軟實力 所謂軟實力就是硬實力以外的軟實力 硬實力是說你電子學的功力 數學的功力\n",
            "\n",
            "\n",
            "========== The 6-th segment of the split (504 words) ==========\n",
            "\n",
            "\n",
            "這個城市能力這種是硬實力 軟實力我們主要就是講各種人際之間的 在人跟人之間的各種能力 包括溝通能力協調能力交朋友的能力 說服人的能力團隊精神領導能力等等\n",
            "\n",
            "那些就是所謂的soft skills 重要不重要重要 你看到任何一個成功的電機工程師 他都有一堆這種 這個纔是他成功的一個非常重要的關鍵 這種東西怎麼來\n",
            "\n",
            "我們剛才講的各種課業外的 各種學習增長的機會 都可以幫助一個人塑造他的soft skills 是有少數人的這些soft skills是天生的 他天生就厲害\n",
            "\n",
            "有沒有 有 但這種人畢竟沒那麼多 對很多人而言 他的soft skills是自己努力慢慢培養起來的 我剛才一開始前面講的那一段 我說我在進臺大電機系以前\n",
            "\n",
            "我幾乎不會交朋友 我不太會說話 我在讀大學的四年裡面改變我自己 讓我變成有很多這方面的能力的人 其實最重要就是我的很多soft skills 都是我自己培養\n",
            "\n",
            "在讀臺大電機系的四年裡面 獲得的非常多這方面的收穫的 那是為什麼我每次都要強調 這個東西有多麼重要 我之前曾經在幾年前的這個 信號與人生裡面有說到這一件事\n",
            "\n",
            "我現在不要重複 但是我簡單的summarize 我說我們電機系的電機工程師的\n",
            "\n",
            "\n",
            "========== The 7-th segment of the split (502 words) ==========\n",
            "\n",
            "\n",
            "一生career的發展 黃金實在是在什麼時候 我認為是在35歲到55歲 這20年是我們的黃金時代 在這以前當然更好 只是說可能各方面尚未具備 還沒有完全訓練的好\n",
            "\n",
            "在這以後是最好的 這以後年紀大了難免有一些要打個折扣等等 就這裡面我們看到 我們的電機系的畢業的同學 過去有幾千人畢業我都看到 我覺得有的人的發展是像這樣\n",
            "\n",
            "有一定的斜率 但到某一個階段它會慢慢saturate 有的人也許開始向上比較晚 但它斜率比較高 它最後會saturate在比較高的地方 也有的人也許開始的比較快\n",
            "\n",
            "但是後來會overshoot之後 會開始收斂在比較低的地方等等 每一個人都不一樣 但是當然也有一種人 你會看到他一直向上走 完全沒有saturate\n",
            "\n",
            "這些人這些差別在哪裡 這些東西差別在哪裡 我以前已經說過這件事 我不要多重複 我說最主要因素有四個 實力、努力、大智 跟self skill這四件事情\n",
            "\n",
            "我認為真正影響這個的 不是因為電子學考得好不好 不是因為信號與系統念得好不好 也就是我剛才講 你把每一門必修課 當成是單一跑道 跑到第一名並不表示怎樣\n",
            "\n",
            "我們最後不看那個的 最後看的是這個 這個是怎麼樣影響 我認為是這四件事\n",
            "\n",
            "\n",
            "========== The 8-th segment of the split (512 words) ==========\n",
            "\n",
            "\n",
            "就是實力、努力、大智跟self skills 這四件事裡面 我們現在可以summarize 我剛才講的 什麼是實力 實力就是所有的這些\n",
            "\n",
            "我們電機工程的專業領域裡面 各種東西的實力 實力怎麼厲害法 就是我剛才講的 你如果都是在做全面的學習的話 你就會學到各種該學到的 最後你的實力就是很強的\n",
            "\n",
            "所以實力最主要就是不要overfitting 要盡量都做 學到該學的全面的學習 努力是沒有疑問 每一個人都瞭解 確實我們可以看到 一個人在未來的幾十年裡面\n",
            "\n",
            "有的人他一直努力 有的人慢慢不太努力等等 這個是有明顯差別的 那self skills我剛才已經講了 就是很多我們平常沒有算成績 覺得大家不重視的事情\n",
            "\n",
            "其實它常常是很重要的 你如果好好的 多在各種課業外的事情上 增長進步的話 你這些東西會很強 你會很厲害的 當然對少數人而言 他天生就有 他可能不需要\n",
            "\n",
            "這是每一個人不一樣的 那這三個我都提過了 那麼大致我還沒有提 其實大致沒有什麼要特別說的 那應該就是我剛才前面有講過 就是每一個人可以有你自己的長程目標\n",
            "\n",
            "那有的人本來就有了 有的人也許我平常沒有想過 那你可以在適當時機開始想 我有沒有想要做什麼事情 哪些事情可能是我的長程目標\n",
            "\n",
            "\n",
            "========== The 9-th segment of the split (169 words) ==========\n",
            "\n",
            "\n",
            "我希望最後讓我花個5年10年 15年或者更長 我把我的很多的努力 都來把某一些事情做得非常漂亮 那是我很想做的事 那就是長程目標\n",
            "\n",
            "如果我覺得做那些事情會讓我非常的 覺得有意義 願意花功夫下去做的 那就是我的長程目標 那有的人如果可以想出這個來的話 那就是他的大致 那越是有這種大致的人\n",
            "\n",
            "也比較容易向上衝 那我感覺起來真正影響的就是這四件事\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Extracts the text from an SRT file and saves it to a new text file\n",
        "pure_text = extract_and_save_text(srt_filename=output_subtitle_path, output_filename=output_raw_text_path)\n",
        "\n",
        "# Split a long document into smaller chunks of a specified length\n",
        "chunks = chunk_text(text=pure_text, max_length=512)\n",
        "\n",
        "# You can see the number of words and contents in each paragraph.\n",
        "print(\"Review the results of splitting the long text into several short texts.\\n\")\n",
        "for index, chunk in enumerate(chunks):\n",
        "    if index == 0:\n",
        "        print(f\"\\n========== The {index + 1}-st segment of the split ({len(chunk)} words) ==========\\n\\n\")\n",
        "        for text in textwrap.wrap(chunk, 80):\n",
        "            print(f\"{text}\\n\")\n",
        "    elif index == 1:\n",
        "        print(f\"\\n========== The {index + 1}-nd segment of the split ({len(chunk)} words) ==========\\n\\n\")\n",
        "        for text in textwrap.wrap(chunk, 80):\n",
        "            print(f\"{text}\\n\")\n",
        "    elif index == 2:\n",
        "        print(f\"\\n========== The {index + 1}-rd segment of the split ({len(chunk)} words) ==========\\n\\n\")\n",
        "        for text in textwrap.wrap(chunk, 80):\n",
        "            print(f\"{text}\\n\")\n",
        "    else:\n",
        "        print(f\"\\n========== The {index + 1}-th segment of the split ({len(chunk)} words) ==========\\n\\n\")\n",
        "        for text in textwrap.wrap(chunk, 80):\n",
        "            print(f\"{text}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wuvx30fkW4kU"
      },
      "source": [
        "# Part4 - Summarization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mr9Kz634zT2"
      },
      "source": [
        "## **You only need to choose one of the following parts.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCPYjOAyXWaE"
      },
      "source": [
        "## **If you want to use ChatGPT, begin with this part.**\n",
        "##### (1) You can refer to https://shorturl.at/X0NDY (Page 44) for obtaining ChatGPT API key.\n",
        "##### (2) You can refer to https://platform.openai.com/docs/models/overview for more details about models you can use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "YCara20SW8AN"
      },
      "outputs": [],
      "source": [
        "def summarization(client, summarization_prompt, model_name=\"gpt-3.5-turbo\", temperature=0.0, top_p=1.0, max_tokens=512):\n",
        "    \"\"\"\n",
        "    (1) Objective:\n",
        "        - Use the OpenAI Chat API to summarize a given text.\n",
        "\n",
        "    (2) Arguments:\n",
        "        - client: OpenAI Chat API client.\n",
        "        - summarization_prompt: The summarization prompt including the text which need to be summarized.\n",
        "        - model_name: The model name, default is \"gpt-3.5-turbo\". You can refer to \"https://platform.openai.com/docs/models/overview\" for more details.\n",
        "        - temperature: Controls randomness in the response. Lower values make responses more deterministic, default is 0.0.\n",
        "        - top_p: Controls diversity via nucleus sampling. Higher values lead to more diverse responses, default is 1.0.\n",
        "        - max_tokens: The maximum number of tokens to generate in the completion, default is 512.\n",
        "\n",
        "    (3) Return:\n",
        "        - The summarized text.\n",
        "\n",
        "    (4) Example:\n",
        "        - If the text is \"ABC\" and the summarization prompt is \"DEF\", system_prompt is \"GHI\", model_name is \"gpt-3.5-turbo\",\n",
        "          temperature is 0.0, top_p is 1.0, and max_tokens is 512, then you can call the function like this:\n",
        "\n",
        "              summarization(client=client, text=\"ABC\", summarization_prompt=\"DEF\", system_prompt=\"GHI\", model_name=\"gpt-3.5-turbo\", temperature=0.0, top_p=1.0, max_tokens=512)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # The user prompt is a concatenation of the summarization_prompt and text.\n",
        "    user_prompt = summarization_prompt\n",
        "\n",
        "    while True:\n",
        "\n",
        "        try:\n",
        "            # Use the OpenAI Chat API to summarize the text.\n",
        "            chat_completion = client.chat.completions.create(\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": user_prompt,\n",
        "                    }\n",
        "                ],\n",
        "                    model=model_name,\n",
        "                    temperature=temperature,\n",
        "                    top_p=top_p,\n",
        "                    max_tokens=max_tokens\n",
        "            )\n",
        "\n",
        "            break\n",
        "\n",
        "        except:\n",
        "            # If the API call fails, wait for 1 second and try again.\n",
        "            print(\"The API call fails, wait for 1 second and try again.\")\n",
        "            time.sleep(1)\n",
        "\n",
        "    return chat_completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "cellView": "form",
        "id": "p3VZeUfBYcih"
      },
      "outputs": [],
      "source": [
        "# @title Parameter Setting of ChatGPT { run: \"auto\" }\n",
        "''' ===== In this block, you can modify your desired parameters and set your OpenAI API key ===== '''\n",
        "\n",
        "# Your OpenAI API key.\n",
        "# @markdown **openai_api_key**: Your OpenAI API key.\n",
        "openai_api_key = \"Insert API key\" # @param {type:\"string\"}\n",
        "\n",
        "# The model name, default is \"gpt-3.5-turbo\". You can refer to \"https://platform.openai.com/docs/models/overview\" for more details.\n",
        "# @markdown **model_name**: The model name, default is \"gpt-3.5-turbo\". You can refer to \"https://platform.openai.com/docs/models/overview\" for more details.\n",
        "model_name = \"gpt-3.5-turbo\" # @param {type: \"string\"}\n",
        "\n",
        "# Controls randomness in the response. Lower values make responses more deterministic.\n",
        "# @markdown **temperature**: Controls randomness in the response. Lower values make responses more deterministic.\n",
        "temperature = 0 # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "\n",
        "# Controls diversity via nucleus sampling. Higher values lead to more diverse responses.\n",
        "# @markdown **top_p**: Controls diversity via nucleus sampling. Higher values lead to more diverse responses.\n",
        "top_p = 0 # @param {type:\"slider\", min:0, max:1, step:0.1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ysnuD_eIeWjY"
      },
      "outputs": [],
      "source": [
        "# Construct openai client.\n",
        "client = OpenAI(api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwDxai-YY4Hl"
      },
      "source": [
        "The code block below takes about **30** seconds to run when using the **gpt-3.5-turbo** model, but the actual time may vary depending on the condition of Colab and the status of the OpenAI API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvCBfcW7Qd-e"
      },
      "source": [
        "### We offer the following two methods for summarization.\n",
        "Reference: https://reurl.cc/VzagLA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9QC8lG_QRZL"
      },
      "source": [
        "#### **If you want to use the method of Multi-Stage Summarization, begin with this part.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "cellView": "form",
        "id": "fUma_oXAQtmg"
      },
      "outputs": [],
      "source": [
        "# @title Prompt Setting of ChatGPT Multi-Stage Summarization: Paragraph { run: \"auto\" }\n",
        "''' You can modify the summarization prompt and maximum number of tokens. '''\n",
        "''' However, DO NOT modify the part of <text>.'''\n",
        "\n",
        "# The maximum number of tokens to generate in the completion.\n",
        "# @markdown **max_tokens**: The maximum number of tokens to generate in the completion.\n",
        "max_tokens = 350 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown #### Changing **summarization_prompt_template**\n",
        "# @markdown You can modify the summarization prompt and maximum number of tokens. However, **DO NOT** modify the part of `<text>`.\n",
        "summarization_prompt_template = \"用 300 個字內寫出這段文字的摘要，其中包括要點和所有重要細節：<text>\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQtk04XATy1j"
      },
      "source": [
        "##### Step1: Split the long text into multiple smaller pieces and obtain summaries for each smaller text piece separately"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUTFgIGl1IRp"
      },
      "source": [
        "The code block below takes about **80** seconds to run when using the (1) **gpt-3.5-turbo** model, (2) length of chunks is 512 and (3) maximum number of tokens is 250, but the actual time may vary depending on the condition of Colab and the status of the OpenAI API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv-Ko3UZYjpg",
        "outputId": "086635ea-ac65-406c-dd5a-be928c5f8406"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------Summary of Segment 1----------------------------\n",
            "\n",
            "學問是需要透過實際做來獲得的。單純地聽或閱讀可能無法真正吸收知識。透過做final project或解決實際問題，才能將所學知識整合並應用。舉例來說，寫程式可以\n",
            "\n",
            "幫助理解複雜演算法。因此，我們應該多動手多實踐，讓學問真正成為自己的。成績單上的數字並不一定能完全反映學問的深度。\n",
            "\n",
            "Length of summary for segment 1: 137\n",
            "Time taken to generate summary for segment 1: 2.55 sec.\n",
            "\n",
            "----------------------------Summary of Segment 2----------------------------\n",
            "\n",
            "許多人認為某些課程不重要，甚至選擇不修或不做 final project，因為覺得太辛苦或不會對成績有幫助。然而，這些課程可能提供最多學習機會，對全面學習很有幫\n",
            "\n",
            "助。重要的是不要漏掉這些機會，培養自己的思考能力和習慣。透過閱讀數學式子和思考課程內容，可以更深入理解並提升思考能力。思考是最重要的，需要花費很多功夫，但對於學\n",
            "\n",
            "習和成長是非常有價值的。\n",
            "\n",
            "Length of summary for segment 2: 172\n",
            "Time taken to generate summary for segment 2: 3.96 sec.\n",
            "\n",
            "----------------------------Summary of Segment 3----------------------------\n",
            "\n",
            "學習不僅僅存在於課業之中，課業外也有許多學習的機會。學習是一種增長、進步和快樂的過程。例如，打球可以提升健康、手腦協調、團隊精神和人際互動能力；爬山可以增加見識\n",
            "\n",
            "和挑戰自己；旅行可以擴展視野和增加經驗。不論是什麼活動，只要讓你感到快樂並有所成長，都值得花時間和精力去學習。因此，將這些活動視為學習的機會，並投入其中，將會為\n",
            "\n",
            "你帶來豐富的收穫。\n",
            "\n",
            "Length of summary for segment 3: 169\n",
            "Time taken to generate summary for segment 3: 4.2 sec.\n",
            "\n",
            "----------------------------Summary of Segment 4----------------------------\n",
            "\n",
            "談戀愛和交朋友都是學習人際互動和溝通的好機會，讓人體驗各種感覺和期待。即使沒有緣分也可以交朋友，對於電機系的同學來說，周圍有很多好同學可以成為交朋友的對象。參加\n",
            "\n",
            "各種活動如舞蹈或劇場表演也能幫助成長和進步。即使不是表演者，幕後工作也同樣重要。因此，談戀愛和交朋友都是有幫助的學習過程。\n",
            "\n",
            "Length of summary for segment 4: 141\n",
            "Time taken to generate summary for segment 4: 23.31 sec.\n",
            "\n",
            "----------------------------Summary of Segment 5----------------------------\n",
            "\n",
            "這段文字談論到在學習過程中，除了專業知識外，參與各種活動和團隊合作也是非常重要的。這些活動可以幫助人們成長和進步，並提供寶貴的學習機會。儘管這些活動沒有考試或成\n",
            "\n",
            "績，但它們對個人發展至關重要。在電機工程領域，成功很少是一個人完成的，需要與他人合作。學習如何進入團隊、成為領導者以及推動想法的能力都是重要的軟實力。除了專業技\n",
            "\n",
            "能外，軟實力也是成功不可或缺的一部分。\n",
            "\n",
            "Length of summary for segment 5: 179\n",
            "Time taken to generate summary for segment 5: 23.68 sec.\n",
            "\n",
            "----------------------------Summary of Segment 6----------------------------\n",
            "\n",
            "成功與否不僅取決於硬實力，更重要的是軟實力，包括人際交往能力、溝通能力、領導能力等。這些soft skills對於成功至關重要，並且可以透過課外活動和學習機會來\n",
            "\n",
            "培養。雖然有些人天生具備這些能力，但大多數人需要努力培養。作者分享了自己在大學期間如何透過努力培養soft\n",
            "\n",
            "skills，並強調這些能力對於電機工程師的成功至關重要。\n",
            "\n",
            "Length of summary for segment 6: 163\n",
            "Time taken to generate summary for segment 6: 23.32 sec.\n",
            "\n",
            "----------------------------Summary of Segment 7----------------------------\n",
            "\n",
            "在這段文字中，作者談到了一生career的發展，認為黃金時期是在35歲到55歲之間。他指出這20年是最好的，因為在這之前可能各方面尚未具備，而在之後年紀大了可能\n",
            "\n",
            "會有一些折扣。作者觀察到電機系的畢業同學的發展，有些人的斜率會慢慢飽和，有些人開始向上比較晚但斜率較高，也有些人開始快但後來會收斂在較低的地方。他認為影響發展的\n",
            "\n",
            "主要因素是實力、努力、大智和self skill，而不是單一學科的成績。最後，作者強調每個人的情況都不同，最重要的是這四個因素如何影響個人的發展。\n",
            "\n",
            "Length of summary for segment 7: 233\n",
            "Time taken to generate summary for segment 7: 5.43 sec.\n",
            "\n",
            "----------------------------Summary of Segment 8----------------------------\n",
            "\n",
            "這段文字主要談到了實力、努力、大智和self skills 四個重要的要素。實力是指在電機工程領域中各種技能和知識的總和，要盡量避免overfitting，全面\n",
            "\n",
            "學習才能提升實力。努力是每個人都應該具備的品質，對未來的發展至關重要。self skills\n",
            "\n",
            "指的是平時被忽視但卻重要的技能，通過不斷學習和進步可以讓自己變得更強大。此外，每個人都應該設定自己的長程目標，這將有助於指導未來的努力和發展方向。\n",
            "\n",
            "Length of summary for segment 8: 200\n",
            "Time taken to generate summary for segment 8: 25.07 sec.\n",
            "\n",
            "----------------------------Summary of Segment 9----------------------------\n",
            "\n",
            "我希望在未來的5年、10年、15年甚至更長的時間裡，專注於努力實現一些我非常想做的事情，這就是我的長程目標。如果我認為這些事情對我來說非常有意義，我願意花時間和\n",
            "\n",
            "精力去實現它們。擁有這種長程目標的人更容易朝著成功的方向前進，這對我來說非常重要。因此，我相信這四個關鍵因素將對我的未來產生真正的影響。\n",
            "\n",
            "Length of summary for segment 9: 148\n",
            "Time taken to generate summary for segment 9: 24.98 sec.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "paragraph_summarizations = []\n",
        "\n",
        "# First, we summarize each section that has been split up separately.\n",
        "for index, chunk in enumerate(chunks):\n",
        "\n",
        "    # Record the start time.\n",
        "    start = time.time()\n",
        "\n",
        "    # Construct summarization prompt.\n",
        "    summarization_prompt = summarization_prompt_template.replace(\"<text>\", chunk)\n",
        "\n",
        "    # We summarize each section that has been split up separately.\n",
        "    response = summarization(client=client, summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
        "\n",
        "    # Calculate the execution time and round it to 2 decimal places.\n",
        "    cost_time = round(time.time() - start, 2)\n",
        "\n",
        "    # Print the summary and its length.\n",
        "    print(f\"----------------------------Summary of Segment {index + 1}----------------------------\\n\")\n",
        "    for text in textwrap.wrap(response, 80):\n",
        "        print(f\"{text}\\n\")\n",
        "    print(f\"Length of summary for segment {index + 1}: {len(response)}\")\n",
        "    print(f\"Time taken to generate summary for segment {index + 1}: {cost_time} sec.\\n\")\n",
        "\n",
        "    # Record the result.\n",
        "    paragraph_summarizations.append(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6QXhSK_eACs",
        "outputId": "059060ce-4264-4690-f887-86d7589573fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary of segment 1: 學問是需要透過實際做來獲得的。單純地聽或閱讀可能無法真正吸收知識。透過做final project或解決實際問題，才能將所學知識整合並應用。舉例來說，寫程式可以幫助理解複雜演算法。因此，我們應該多動手多實踐，讓學問真正成為自己的。成績單上的數字並不一定能完全反映學問的深度。\n",
            "Summary of segment 2: 許多人認為某些課程不重要，甚至選擇不修或不做 final project，因為覺得太辛苦或不會對成績有幫助。然而，這些課程可能提供最多學習機會，對全面學習很有幫助。重要的是不要漏掉這些機會，培養自己的思考能力和習慣。透過閱讀數學式子和思考課程內容，可以更深入理解並提升思考能力。思考是最重要的，需要花費很多功夫，但對於學習和成長是非常有價值的。\n",
            "Summary of segment 3: 學習不僅僅存在於課業之中，課業外也有許多學習的機會。學習是一種增長、進步和快樂的過程。例如，打球可以提升健康、手腦協調、團隊精神和人際互動能力；爬山可以增加見識和挑戰自己；旅行可以擴展視野和增加經驗。不論是什麼活動，只要讓你感到快樂並有所成長，都值得花時間和精力去學習。因此，將這些活動視為學習的機會，並投入其中，將會為你帶來豐富的收穫。\n",
            "Summary of segment 4: 談戀愛和交朋友都是學習人際互動和溝通的好機會，讓人體驗各種感覺和期待。即使沒有緣分也可以交朋友，對於電機系的同學來說，周圍有很多好同學可以成為交朋友的對象。參加各種活動如舞蹈或劇場表演也能幫助成長和進步。即使不是表演者，幕後工作也同樣重要。因此，談戀愛和交朋友都是有幫助的學習過程。\n",
            "Summary of segment 5: 這段文字談論到在學習過程中，除了專業知識外，參與各種活動和團隊合作也是非常重要的。這些活動可以幫助人們成長和進步，並提供寶貴的學習機會。儘管這些活動沒有考試或成績，但它們對個人發展至關重要。在電機工程領域，成功很少是一個人完成的，需要與他人合作。學習如何進入團隊、成為領導者以及推動想法的能力都是重要的軟實力。除了專業技能外，軟實力也是成功不可或缺的一部分。\n",
            "Summary of segment 6: 成功與否不僅取決於硬實力，更重要的是軟實力，包括人際交往能力、溝通能力、領導能力等。這些soft skills對於成功至關重要，並且可以透過課外活動和學習機會來培養。雖然有些人天生具備這些能力，但大多數人需要努力培養。作者分享了自己在大學期間如何透過努力培養soft skills，並強調這些能力對於電機工程師的成功至關重要。\n",
            "Summary of segment 7: 在這段文字中，作者談到了一生career的發展，認為黃金時期是在35歲到55歲之間。他指出這20年是最好的，因為在這之前可能各方面尚未具備，而在之後年紀大了可能會有一些折扣。作者觀察到電機系的畢業同學的發展，有些人的斜率會慢慢飽和，有些人開始向上比較晚但斜率較高，也有些人開始快但後來會收斂在較低的地方。他認為影響發展的主要因素是實力、努力、大智和self skill，而不是單一學科的成績。最後，作者強調每個人的情況都不同，最重要的是這四個因素如何影響個人的發展。\n",
            "Summary of segment 8: 這段文字主要談到了實力、努力、大智和self skills 四個重要的要素。實力是指在電機工程領域中各種技能和知識的總和，要盡量避免overfitting，全面學習才能提升實力。努力是每個人都應該具備的品質，對未來的發展至關重要。self skills 指的是平時被忽視但卻重要的技能，通過不斷學習和進步可以讓自己變得更強大。此外，每個人都應該設定自己的長程目標，這將有助於指導未來的努力和發展方向。\n",
            "Summary of segment 9: 我希望在未來的5年、10年、15年甚至更長的時間裡，專注於努力實現一些我非常想做的事情，這就是我的長程目標。如果我認為這些事情對我來說非常有意義，我願意花時間和精力去實現它們。擁有這種長程目標的人更容易朝著成功的方向前進，這對我來說非常重要。因此，我相信這四個關鍵因素將對我的未來產生真正的影響。\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# First, we collect all the summarizations obtained before and print them.\n",
        "\n",
        "collected_summarization = \"\"\n",
        "for index, paragraph_summarization in enumerate(paragraph_summarizations):\n",
        "    collected_summarization += f\"Summary of segment {index + 1}: {paragraph_summarization}\\n\"\n",
        "\n",
        "print(collected_summarization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itdqp3H5T2T7"
      },
      "source": [
        "##### Step2: After obtaining summaries for each smaller text piece separately, process these summaries to generate the final summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "cellView": "form",
        "id": "l0ghZaKfVEyN"
      },
      "outputs": [],
      "source": [
        "# @title Prompt Setting of ChatGPT Multi-Stage Summarization: Total { run: \"auto\" }\n",
        "''' You can modify the summarization prompt and maximum number of tokens. '''\n",
        "''' However, DO NOT modify the part of <text>.'''\n",
        "\n",
        "# We set the maximum number of tokens to ensure that the final summary does not exceed 550 tokens.\n",
        "# @markdown **max_tokens**: We set the maximum number of tokens to ensure that the final summary does not exceed 550 tokens.\n",
        "max_tokens = 550 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown ### Changing **summarization_prompt_template**\n",
        "# @markdown You can modify the summarization prompt and maximum number of tokens. However, **DO NOT** modify the part of `<text>`.\n",
        "summarization_prompt_template = \"在 500 字以內寫出以下文字的簡潔摘要：<text>\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka0JcOvYVIWu"
      },
      "source": [
        "The code block below takes about **10** seconds to run when using the (1) **gpt-3.5-turbo** model and (2) maximum number of tokens is 500, but the actual time may vary depending on the condition of Colab and the status of the OpenAI API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zHPMRDWeCuq",
        "outputId": "084b003e-eecb-4d85-ff0f-f805526e3f6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------Final Summary----------------------------\n",
            "\n",
            "Summary of segment 1: Knowledge is best acquired through hands-on experience\n",
            "rather than just listening or reading. By working on final projects or solving\n",
            "real-world problems, one can integrate and apply the knowledge learned. For\n",
            "example, writing code helps understand complex algorithms. Therefore, it is\n",
            "essential to practice and apply knowledge to truly make it one's own, as grades\n",
            "do not always reflect the depth of understanding.  Summary of segment 2: Many\n",
            "people overlook certain courses or final projects because they find them\n",
            "challenging or believe they won't benefit their grades. However, these courses\n",
            "often provide valuable learning opportunities and contribute to a well-rounded\n",
            "education. It is crucial not to miss out on these chances to develop critical\n",
            "thinking skills. Reading mathematical formulas and contemplating course content\n",
            "can deepen understanding and enhance critical thinking abilities, which are\n",
            "essential for learning and growth.  Summary of segment 3: Learning extends\n",
            "beyond academics and presents itself in various activities outside the\n",
            "classroom. Engaging in activities like sports, hiking, or traveling offers\n",
            "opportunities for personal growth, skill development, and expanding one's\n",
            "horizons. Any activity that brings joy and growth is worth investing time and\n",
            "effort into as it contributes to a fulfilling learning experience.  Summary of\n",
            "segment 4: Building relationships and making friends provide valuable\n",
            "opportunities to learn interpersonal skills and communication. Even without\n",
            "romantic connections, forming friendships with classmates in the electrical\n",
            "engineering field can be enriching. Participating in activities like dance or\n",
            "theater performances, whether on stage or behind the scenes, fosters personal\n",
            "growth and improvement, making love and friendship valuable learning\n",
            "experiences.  Summary of segment 5: In addition to technical knowledge, engaging\n",
            "in various activities and teamwork is crucial for personal growth and learning\n",
            "opportunities. Collaboration and teamwork are essential in the field of\n",
            "electrical engineering, emphasizing the importance of developing soft skills\n",
            "like teamwork, leadership, and idea implementation. Soft skills, alongside\n",
            "technical skills, are integral to success and personal development.  Summary of\n",
            "segment 6: Success relies not only on technical skills but also on soft skills\n",
            "like interpersonal communication, leadership, and teamwork. Cultivating these\n",
            "soft skills through extracurricular activities and learning opportunities is\n",
            "vital for success. While some individuals may possess these skills naturally,\n",
            "most people need to work hard to develop them. The author shares their\n",
            "experience in developing soft skills during university and emphasizes their\n",
            "significance for success in electrical engineering.  Summary of segment 7: The\n",
            "author discusses career development, highlighting the prime years between 35 and\n",
            "55 as the golden period for growth and success. Factors like competence, effort,\n",
            "intelligence, and soft skills influence individual development more than\n",
            "academic grades. Observing the trajectories of electrical engineering graduates,\n",
            "the author notes varying rates of growth and emphasizes the importance of\n",
            "personal circumstances and the four key factors in shaping one's development.\n",
            "Summary of\n",
            "\n",
            "Length of final summary: 3311\n",
            "Time taken to generate the final summary: 9.51 sec.\n"
          ]
        }
      ],
      "source": [
        "# Finally, we compile a final summary from the summaries of each section.\n",
        "\n",
        "# Record the start time.\n",
        "start = time.time()\n",
        "\n",
        "# Run final summarization.\n",
        "summarization_prompt = summarization_prompt_template.replace(\"<text>\", collected_summarization)\n",
        "final_summarization = summarization(client=client, summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
        "\n",
        "# Calculate the execution time and round it to 2 decimal places.\n",
        "cost_time = round(time.time() - start, 2)\n",
        "\n",
        "# Print the summary and its length.\n",
        "print(f\"----------------------------Final Summary----------------------------\\n\")\n",
        "for text in textwrap.wrap(final_summarization, 80):\n",
        "        print(f\"{text}\")\n",
        "print(f\"\\nLength of final summary: {len(final_summarization)}\")\n",
        "print(f\"Time taken to generate the final summary: {cost_time} sec.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qi7eERB8eGdK",
        "outputId": "c0711622-a086-4186-e7dc-ec3d8d0e4e04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final summary has been saved to ./final-summary-信號與人生-chatgpt-multi-stage.txt\n",
            "\n",
            "===== Below is the final summary (372 words) =====\n",
            "\n",
            "總結這段文字，作者強調了學習的重要性，並提出了一些具體的建議。首先，學問需要透過實際做來獲得，透過做final project或\n",
            "解決實際問題才能將所學知識整合並應用。其次，不要漏掉任何學習機會，即使覺得困難或不重要，這些課程可能提供最多學習機會。再者，學習\n",
            "不僅存在於課業之中，課業外也有許多學習的機會，只要讓你感到快樂並有所成長，都值得花時間和精力去學習。最後，談戀愛和交朋友也是學習\n",
            "人際互動和溝通的好機會，對於個人成長和進步都有幫助。總的來說，除了專業知識外，參與各種活動和團隊合作也是非常重要的，這些活動可以\n",
            "幫助人們成長和進步，並提供寶貴的學習機會。最終，作者強調了實力、努力、大智和self skills 四個重要的要素，並建議每個人\n",
            "都應該設定自己的長程目標，這將有助於指導未來的努力和發展方向。這些建議將對個人的未來發展產生真正的影響。\n"
          ]
        }
      ],
      "source": [
        "''' In this block, you can modify your desired output path of final summary. '''\n",
        "\n",
        "output_path = f\"./final-summary-{suffix}-chatgpt-multi-stage.txt\"\n",
        "\n",
        "# If you need to convert Simplified Chinese to Traditional Chinese, please set this option to True; otherwise, set it to False.\n",
        "convert_to_tradition_chinese = False\n",
        "\n",
        "if convert_to_tradition_chinese == True:\n",
        "    # Creating an instance of OpenCC for Simplified to Traditional Chinese conversion.\n",
        "    cc = OpenCC('s2t')\n",
        "    final_summarization = cc.convert(final_summarization)\n",
        "\n",
        "# Output your final summary\n",
        "with open(output_path, \"w\") as fp:\n",
        "    fp.write(final_summarization)\n",
        "\n",
        "# Show the result.\n",
        "print(f\"Final summary has been saved to {output_path}\")\n",
        "print(f\"\\n===== Below is the final summary ({len(final_summarization)} words) =====\\n\")\n",
        "for text in textwrap.wrap(final_summarization, 64):\n",
        "    print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRzf_0cTV6TS"
      },
      "source": [
        "#### **If you want to use the method of Refinement, begin with this part.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "cellView": "form",
        "id": "k79C13kWW_Ye"
      },
      "outputs": [],
      "source": [
        "# @title Prompt Setting of ChatGPT Refinement { run: \"auto\" }\n",
        "''' You can modify the summarization prompt and maximum number of tokens. '''\n",
        "''' However, DO NOT modify the part of <text>.'''\n",
        "\n",
        "# We set the maximum number of tokens.\n",
        "# @markdown **max_tokens**: We set the maximum number of tokens.\n",
        "max_tokens = 550 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown ### Changing **summarization_prompt_template** and **summarization_prompt_refine_template**\n",
        "# @markdown You can modify the summarization prompt and maximum number of tokens. However, **DO NOT** modify the part of `<text>`.\n",
        "\n",
        "# Initial prompt.\n",
        "# @markdown **summarization_prompt_template**: Initial prompt.\n",
        "summarization_prompt_template = \"請在 300 字以內，提供以下文字的簡潔摘要:<text>\" # @param {type:\"string\"}\n",
        "\n",
        "# Refinement prompt.\n",
        "# @markdown **summarization_prompt_refinement_template**: Refinement prompt.\n",
        "summarization_prompt_refinement_template = \"請在 500 字以內，結合原先的摘要和新的內容，提供簡潔的摘要:<text>\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEtfC9WeZkNH"
      },
      "source": [
        "The code block below takes about **200** seconds to run when using the (1) **gpt-3.5-turbo** model and (2) maximum number of tokens is 500, but the actual time may vary depending on the condition of Colab and the status of the OpenAI API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rugUlJ6HeZPF"
      },
      "source": [
        "Pipeline of the method of Refinement.\n",
        "\n",
        "Step1: It starts by running a prompt on a small portion of the data, generating initial output.\n",
        "\n",
        "Step2: For each following document, the previous output is fed in along with the new document.\n",
        "\n",
        "Step3: The LLM is instructed to refine the output based on the new document's information.\n",
        "\n",
        "Step4: This process continues iteratively until all documents have been processed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aFmk1ATAOdd",
        "outputId": "c637f06e-c515-419b-a0a9-60a65a7360bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------Summary of Segment 1----------------------------\n",
            "\n",
            "我希望在未來的5年、10年、15年甚至更長的時間裡，將我的努力集中在實現一些非常重要的事情上。這些事情是我非常想做的，也是我認為有意義的。如果我認為這些事情值得\n",
            "\n",
            "投入時間和精力，那麼這就是我的長程目標。擁有這種長程目標的人更容易朝著成功的方向前進。對我來說，這四件事情是真正影響我未來的關鍵。\n",
            "\n",
            "Length of summary for segment 1: 145\n",
            "Time taken to generate summary for segment 1: 3.33 sec.\n",
            "\n",
            "----------------------------Summary of the First 2 Segments----------------------------\n",
            "\n",
            "學問是做出來的，透過實際動手做才能真正掌握知識。單純聽或閱讀可能會讓知識流失，但透過做一個最終項目或寫一個程式來整合所學，才能真正理解和掌握知識。透過實際動手做\n",
            "\n",
            "，才能讓知識變成自己的。因此，我們應該記得要多動手多做，透過實踐來學習，而不僅僅追求成績單上的數字。  很多人可能會覺得某些課程的final project太困\n",
            "\n",
            "難或不重要而選擇不修讀，然而這些挑戰其實是讓你成長和學習的機會。即使這些任務可能不會立即帶來具體成果或成績，但對於全面的學習和思考能力的培養卻是非常有幫助的。在\n",
            "\n",
            "學習的過程中，不僅要讀書，還要思考並實際動手做，這樣才能真正理解和掌握知識。因此，不要漏掉任何學習的機會，並努力培養自己的思考能力和習慣，這才是最重要的。\n",
            "\n",
            "Length of summary for the first 2 segments: 317\n",
            "Time taken to generate summary for the first 2 segments: 5.96 sec.\n",
            "\n",
            "----------------------------Summary of the First 3 Segments----------------------------\n",
            "\n",
            "學問是做出來的，透過實際動手做才能真正掌握知識。單純聽或閱讀可能會讓知識流失，但透過做一個最終項目或寫一個程式來整合所學，才能真正理解和掌握知識。透過實際動手做\n",
            "\n",
            "，才能讓知識變成自己的。因此，我們應該記得要多動手多做，透過實踐來學習，而不僅僅追求成績單上的數字。  很多人可能會覺得某些課程的final project太困\n",
            "\n",
            "難或不重要而選擇不修讀，然而這些挑戰其實是讓你成長和學習的機會。即使這些任務可能不會立即帶來具體成果或成績，但對於全面的學習和思考能力的培養卻是非常有幫助的。在\n",
            "\n",
            "學習的過程中，不僅要讀書，還要思考並實際動手做，這樣才能真正理解和掌握知識。因此，不要漏掉任何學習的機會，並努力培養自己的思考能力和習慣，這才是最重要的。\n",
            "\n",
            "除了課業內的學習，課業外也有很多值得學習的機會。學習不僅限於書本知識，還包括各種生活經驗和技能的獲得。例如，打球、爬山、旅行等活動都是有\n",
            "\n",
            "Length of summary for the first 3 segments: 387\n",
            "Time taken to generate summary for the first 3 segments: 27.51 sec.\n",
            "\n",
            "----------------------------Summary of the First 4 Segments----------------------------\n",
            "\n",
            "摘要: 學問是透過實際動手做才能真正掌握知識，不僅要讀書還要思考並實際應用。即使遇到困難的final project，也是成長和學習的機會。除了課業內的學習，課\n",
            "\n",
            "業外的活動也是學習的機會，例如談戀愛和交朋友都能讓人學習人際互動和溝通技巧。在校園裡參加各種活動也能幫助學生成長和進步，不論是參加舞蹈或劇場表演，或是參與幕後規\n",
            "\n",
            "劃和軟體組，都能讓人有所增長和進步。因此，多參與各種活動，多交朋友，透過實踐來學習，才能真正掌握知識並成長。\n",
            "\n",
            "Length of summary for the first 4 segments: 214\n",
            "Time taken to generate summary for the first 4 segments: 24.83 sec.\n",
            "\n",
            "----------------------------Summary of the First 5 Segments----------------------------\n",
            "\n",
            "摘要: 透過實際動手做才能真正掌握知識，不僅要讀書還要思考並實際應用。即使遇到困難的final project，也是成長和學習的機會。課業外的活動也是學習的機會\n",
            "\n",
            "，例如談戀愛和交朋友都能讓人學習人際互動和溝通技巧。在校園裡參加各種活動也能幫助學生成長和進步，不論是參加舞蹈或劇場表演，或是參與幕後規劃和軟體組，都能讓人有所\n",
            "\n",
            "增長和進步。參與服裝道具組或其他校內外活動都是學習的機會，雖然這些活動沒有考試成績，但對於發展軟實力和團隊合作能力非常重要。在電機工程領域，與他人合作是成功的關\n",
            "\n",
            "鍵，學習如何進入團隊、成為領導者並推動目標的能力都是軟實力的一部分，這些技能對於個人發展和職業生涯都至關重要。\n",
            "\n",
            "Length of summary for the first 5 segments: 295\n",
            "Time taken to generate summary for the first 5 segments: 6.02 sec.\n",
            "\n",
            "----------------------------Summary of the First 6 Segments----------------------------\n",
            "\n",
            "摘要: 透過實際動手做才能真正掌握知識，不僅要讀書還要思考並實際應用。即使遇到困難的final project，也是成長和學習的機會。課業外的活動也是學習的機會\n",
            "\n",
            "，例如談戀愛和交朋友都能讓人學習人際互動和溝通技巧。在校園裡參加各種活動也能幫助學生成長和進步，不論是參加舞蹈或劇場表演，或是參與幕後規劃和軟體組，都能讓人有所\n",
            "\n",
            "增長和進步。參與服裝道具組或其他校內外活動都是學習的機會，雖然這些活動沒有考試成績，但對於發展軟實力和團隊合作能力非常重要。在電機工程領域，與他人合作是成功的關\n",
            "\n",
            "鍵，學習如何進入團隊、成為領導者並推動目標的能力都是軟實力的一部分，這些技能對於個人發展和職業生涯都至關重要。在現代社會中，軟實力的重要性愈發凸顯，這包括人際溝\n",
            "\n",
            "通、協調能力、交友技巧、說服力、團隊合作和領導能力等。成功的電機工程師擁有豐富的軟實力，這是他們成功的關鍵之一。透過各種課業\n",
            "\n",
            "Length of summary for the first 6 segments: 382\n",
            "Time taken to generate summary for the first 6 segments: 28.86 sec.\n",
            "\n",
            "----------------------------Summary of the First 7 Segments----------------------------\n",
            "\n",
            "透過實際動手做才能真正掌握知識，不僅要讀書還要思考並實際應用。即使遇到困難的final project，也是成長和學習的機會。課業外的活動也是學習的機會，例如談\n",
            "\n",
            "戀愛和交朋友都能讓人學習人際互動和溝通技巧。在校園裡參加各種活動也能幫助學生成長和進步，不論是參加舞蹈或劇場表演，或是參與幕後規劃和軟體組，都能讓人有所增長和進\n",
            "\n",
            "步。參與服裝道具組或其他校內外活動都是學習的機會，雖然這些活動沒有考試成績，但對於發展軟實力和團隊合作能力非常重要。在電機工程領域，與他人合作是成功的關鍵，學習\n",
            "\n",
            "如何進入團隊、成為領導者並推動目標的能力都是軟實力的一部分，這些技能對於個人發展和職業生涯都至關重要。在現代社會中，軟實力的重要性愈發凸顯，這包括人際溝通、協調\n",
            "\n",
            "能力、交友技巧、說服力、團隊合作和領導能力等。成功的電機工程師擁有豐富的軟實力，這是他們成功的關鍵之一。透過各種課業和校園\n",
            "\n",
            "Length of summary for the first 7 segments: 381\n",
            "Time taken to generate summary for the first 7 segments: 29.82 sec.\n",
            "\n",
            "----------------------------Summary of the First 8 Segments----------------------------\n",
            "\n",
            "透過實際動手做才能真正掌握知識，不僅要讀書還要思考並實際應用。即使遇到困難的final project，也是成長和學習的機會。課業外的活動也是學習的機會，例如談\n",
            "\n",
            "戀愛和交朋友都能讓人學習人際互動和溝通技巧。在校園裡參加各種活動也能幫助學生成長和進步，不論是參加舞蹈或劇場表演，或是參與幕後規劃和軟體組，都能讓人有所增長和進\n",
            "\n",
            "步。參與服裝道具組或其他校內外活動都是學習的機會，雖然這些活動沒有考試成績，但對於發展軟實力和團隊合作能力非常重要。在電機工程領域，與他人合作是成功的關鍵，學習\n",
            "\n",
            "如何進入團隊、成為領導者並推動目標的能力都是軟實力的一部分，這些技能對於個人發展和職業生涯都至關重要。在現代社會中，軟實力的重要性愈發凸顯，這包括人際溝通、協調\n",
            "\n",
            "能力、交友技巧、說服力、團隊合作和領導能力等。成功的電機工程師擁有豐富的軟實力，這是他們成功的關鍵之一。透過各種課業和校園\n",
            "\n",
            "Length of summary for the first 8 segments: 381\n",
            "Time taken to generate summary for the first 8 segments: 7.48 sec.\n",
            "\n",
            "----------------------------Summary of the First 9 Segments----------------------------\n",
            "\n",
            "透過實際動手做才能真正掌握知識，不僅要讀書還要思考並實際應用。即使遇到困難的final project，也是成長和學習的機會。課業外的活動也是學習的機會，例如談\n",
            "\n",
            "戀愛和交朋友都能讓人學習人際互動和溝通技巧。在校園裡參加各種活動也能幫助學生成長和進步，不論是參加舞蹈或劇場表演，或是參與幕後規劃和軟體組，都能讓人有所增長和進\n",
            "\n",
            "步。參與服裝道具組或其他校內外活動都是學習的機會，雖然這些活動沒有考試成績，但對於發展軟實力和團隊合作能力非常重要。在電機工程領域，與他人合作是成功的關鍵，學習\n",
            "\n",
            "如何進入團隊、成為領導者並推動目標的能力都是軟實力的一部分，這些技能對於個人發展和職業生涯都至關重要。在現代社會中，軟實力的重要性愈發凸顯，這包括人際溝通、協調\n",
            "\n",
            "能力、交友技巧、說服力、團隊合作和領導能力等。成功的電機工程師擁有豐富的軟實力，這是他們成功的關鍵之一。透過各種課業和校園\n",
            "\n",
            "Length of summary for the first 9 segments: 381\n",
            "Time taken to generate summary for the first 9 segments: 28.42 sec.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "paragraph_summarizations = []\n",
        "\n",
        "# First, we summarize each section that has been split up separately.\n",
        "for index, chunk in enumerate(chunks):\n",
        "\n",
        "    if index == 0:\n",
        "        # Record the start time.\n",
        "        start = time.time()\n",
        "\n",
        "        # Construct summarization prompt.\n",
        "        summarization_prompt = summarization_prompt_template.replace(\"<text>\", chunk)\n",
        "\n",
        "        # Step1: It starts by running a prompt on a small portion of the data, generating initial output.\n",
        "        first_paragraph_summarization = summarization(client=client, summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
        "\n",
        "        # Record the result.\n",
        "        paragraph_summarizations.append(first_paragraph_summarization)\n",
        "\n",
        "        # Calculate the execution time and round it to 2 decimal places.\n",
        "        cost_time = round(time.time() - start, 2)\n",
        "\n",
        "        # Print the summary and its length.\n",
        "        print(f\"----------------------------Summary of Segment {index + 1}----------------------------\\n\")\n",
        "        for text in textwrap.wrap(response, 80):\n",
        "            print(f\"{text}\\n\")\n",
        "        print(f\"Length of summary for segment {index + 1}: {len(response)}\")\n",
        "        print(f\"Time taken to generate summary for segment {index + 1}: {cost_time} sec.\\n\")\n",
        "\n",
        "\n",
        "    else:\n",
        "        # Record the start time.\n",
        "        start = time.time()\n",
        "\n",
        "        # Step2: For each following document, the previous output is fed in along with the new document.\n",
        "        chunk_text = f\"\"\"前 {index} 段的摘要: {paragraph_summarizations[-1]}\\n第 {index + 1} 段的內容: {chunk}\"\"\"\n",
        "\n",
        "        # Construct refinement prompt for summarization.\n",
        "        summarization_prompt = summarization_prompt_refinement_template.replace(\"<text>\", chunk_text)\n",
        "\n",
        "        # Step3: The LLM is instructed to refine the output based on the new document's information.\n",
        "        paragraph_summarization = summarization(client=client, summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
        "\n",
        "        # Record the result.\n",
        "        paragraph_summarizations.append(paragraph_summarization)\n",
        "\n",
        "        # Calculate the execution time and round it to 2 decimal places.\n",
        "        cost_time = round(time.time() - start, 2)\n",
        "\n",
        "        # print results.\n",
        "        print(f\"----------------------------Summary of the First {index + 1} Segments----------------------------\\n\")\n",
        "        for text in textwrap.wrap(paragraph_summarization, 80):\n",
        "            print(f\"{text}\\n\")\n",
        "        print(f\"Length of summary for the first {index + 1} segments: {len(paragraph_summarization)}\")\n",
        "        print(f\"Time taken to generate summary for the first {index + 1} segments: {cost_time} sec.\\n\")\n",
        "\n",
        "    # Step4: This process continues iteratively until all documents have been processed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaXWOLIOa4dM",
        "outputId": "78c22f67-bbd3-4f0c-fa04-609f63eebba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final summary has been saved to ./final-summary-信號與人生-chatgpt-refinement.txt\n",
            "\n",
            "===== Below is the final summary (381 words) =====\n",
            "\n",
            "透過實際動手做才能真正掌握知識，不僅要讀書還要思考並實際應用。即使遇到困難的final project，也是成長和學習的機會。課業外的活動也是學習的機會，例如談\n",
            "戀愛和交朋友都能讓人學習人際互動和溝通技巧。在校園裡參加各種活動也能幫助學生成長和進步，不論是參加舞蹈或劇場表演，或是參與幕後規劃和軟體組，都能讓人有所增長和進\n",
            "步。參與服裝道具組或其他校內外活動都是學習的機會，雖然這些活動沒有考試成績，但對於發展軟實力和團隊合作能力非常重要。在電機工程領域，與他人合作是成功的關鍵，學習\n",
            "如何進入團隊、成為領導者並推動目標的能力都是軟實力的一部分，這些技能對於個人發展和職業生涯都至關重要。在現代社會中，軟實力的重要性愈發凸顯，這包括人際溝通、協調\n",
            "能力、交友技巧、說服力、團隊合作和領導能力等。成功的電機工程師擁有豐富的軟實力，這是他們成功的關鍵之一。透過各種課業和校園\n"
          ]
        }
      ],
      "source": [
        "''' In this block, you can modify your desired output path of final summary. '''\n",
        "\n",
        "output_path = f\"./final-summary-{suffix}-chatgpt-refinement.txt\"\n",
        "\n",
        "# If you need to convert Simplified Chinese to Traditional Chinese, please set this option to True; otherwise, set it to False.\n",
        "convert_to_tradition_chinese = False\n",
        "\n",
        "if convert_to_tradition_chinese == True:\n",
        "    # Creating an instance of OpenCC for Simplified to Traditional Chinese conversion.\n",
        "    cc = OpenCC('s2t')\n",
        "    paragraph_summarizations[-1] = cc.convert(paragraph_summarizations[-1])\n",
        "\n",
        "# Output your final summary\n",
        "with open(output_path, \"w\") as fp:\n",
        "    fp.write(paragraph_summarizations[-1])\n",
        "\n",
        "# Show the result.\n",
        "print(f\"Final summary has been saved to {output_path}\")\n",
        "print(f\"\\n===== Below is the final summary ({len(paragraph_summarizations[-1])} words) =====\\n\")\n",
        "for text in textwrap.wrap(paragraph_summarizations[-1], 80):\n",
        "    print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCM4kPuBXh7R"
      },
      "source": [
        "## **If you want to use Gemini, begin with this part.**\n",
        "##### (1) You can refer to https://shorturl.at/X0NDY (Page 35) for obtaining Gemini API key.\n",
        "##### (2) You can refer to https://ai.google.dev/models/gemini for more details about which models you can use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anuFrhHNkMgY"
      },
      "outputs": [],
      "source": [
        "def summarization(summarization_prompt, model_name=\"gemini-pro\", temperature=0.0, top_p=1.0, max_tokens=512):\n",
        "    \"\"\"\n",
        "    (1) Objective:\n",
        "        - Use the OpenAI Chat API to summarize a given text.\n",
        "\n",
        "    (2) Arguments:\n",
        "        - summarization_prompt: The summarization prompt.\n",
        "        - model_name: The model name, default is \"gemini-pro\". You can refer to \"https://ai.google.dev/models/gemini\" for more details.\n",
        "        - temperature: Controls randomness in the response. Lower values make responses more deterministic, default is 0.0.\n",
        "        - top_p: Controls diversity via nucleus sampling. Higher values lead to more diverse responses, default is 1.0.\n",
        "        - max_tokens: The maximum number of tokens to generate in the completion, default is 512.\n",
        "\n",
        "    (3) Return:\n",
        "        - The summarized text.\n",
        "\n",
        "    (4) Example:\n",
        "        - If the text is \"ABC\" and the summarization prompt is \"DEF\", model_name is \"gemini-pro\",\n",
        "          temperature is 0.0, top_p is 1.0, and max_tokens is 512, then you can call the function like this:\n",
        "\n",
        "              summarization(text=\"ABC\", summarization_prompt=\"DEF\", model_name=\"gemini-pro\", temperature=0.0, top_p=1.0, max_tokens=512)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # The user prompt is a concatenation of the summarization_prompt and text.\n",
        "    user_prompt = summarization_prompt\n",
        "\n",
        "    # Load the generative model.\n",
        "    model = genai.GenerativeModel(model_name)\n",
        "\n",
        "    # Set the generation configuration.\n",
        "    generation_config = genai.GenerationConfig(temperature=temperature, top_p=top_p, max_output_tokens=max_tokens)\n",
        "\n",
        "    while True:\n",
        "\n",
        "        try:\n",
        "            # Use the OpenAI Chat API to summarize the text.\n",
        "            response = model.generate_content(contents=user_prompt, generation_config=generation_config)\n",
        "\n",
        "            break\n",
        "\n",
        "        except:\n",
        "            # If the API call fails, wait for 1 second and try again.\n",
        "            print(\"The API call fails, wait for 1 second and try again.\")\n",
        "            time.sleep(1)\n",
        "\n",
        "    return response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "plyvWCvXllz3"
      },
      "outputs": [],
      "source": [
        "# @title Parameter Setting of Gemini { run: \"auto\" }\n",
        "''' In this block, you can modify your desired parameters and set your api key. '''\n",
        "\n",
        "# Your google api key.\n",
        "# @markdown **google_api_key**: Your google api key.\n",
        "google_api_key = \"YOUR_GOOGLE_API_KEY\" # @param {type:\"string\"}\n",
        "\n",
        "# The model name. You can refer to \"https://ai.google.dev/models/gemini\" for more details.\n",
        "# @markdown **model_name**: The model name. You can refer to \"https://ai.google.dev/models/gemini\" for more details.\n",
        "model_name = \"gemini-pro\" # @param {type:\"string\"}\n",
        "\n",
        "# Controls randomness in the response. Lower values make responses more deterministic\n",
        "# @markdown **temperature**: Controls randomness in the response. Lower values make responses more deterministic.\n",
        "temperature = 0.0 # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "\n",
        "# Controls diversity via nucleus sampling. Higher values lead to more diverse responses\n",
        "# @markdown **top_p**: Controls diversity via nucleus sampling. Higher values lead to more diverse responses.\n",
        "top_p = 1.0 # @param {type:\"slider\", min:0, max:1, step:0.1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eed0NjqJtGfM"
      },
      "outputs": [],
      "source": [
        "# Set Google API key.\n",
        "genai.configure(api_key=google_api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csw7hxrHsJym"
      },
      "source": [
        "### We offer the following two methods for summarization.\n",
        "Reference: https://reurl.cc/VzagLA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGHFGCyasp9h"
      },
      "source": [
        "#### **If you want to use the method of Multi-Stage Summarization, begin with this part.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TsX6dBgs1iw"
      },
      "outputs": [],
      "source": [
        "# @title Prompt Setting of Gemini Multi-Stage Summarization: Paragraph { run: \"auto\" }\n",
        "''' You can modify the summarization prompt and maximum number of tokens. '''\n",
        "''' However, DO NOT modify the part of <text>.'''\n",
        "\n",
        "# The maximum number of tokens to generate in the completion.\n",
        "# @markdown **max_tokens**: The maximum number of tokens to generate in the completion.\n",
        "max_tokens = 350 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown #### Changing **summarization_prompt_template**\n",
        "# @markdown You can modify the summarization prompt and maximum number of tokens. However, **DO NOT** modify the part of `<text>`.\n",
        "summarization_prompt_template = \"用 300 個字內寫出這段文字的摘要，其中包括要點和所有重要細節：<text>\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkQdOOixuJU9"
      },
      "source": [
        "##### Step1: Split the long text into multiple smaller pieces and obtain summaries for each smaller text piece separately\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olrUkpe615-E"
      },
      "source": [
        "The code block below takes about **40** seconds to run when using the (1) **gemini-pro** model, (2) length of chunks is 512 and (3) maximum number of tokens is 350, but the actual time may vary depending on the condition of Colab and the status of the Google API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KOp_d6XloCn"
      },
      "outputs": [],
      "source": [
        "paragraph_summarizations = []\n",
        "\n",
        "# First, we summarize each section that has been split up separately.\n",
        "for index, chunk in enumerate(chunks):\n",
        "\n",
        "    # Record the start time.\n",
        "    start = time.time()\n",
        "\n",
        "    # Construct summarization prompt.\n",
        "    summarization_prompt = summarization_prompt_template.replace(\"<text>\", chunk)\n",
        "\n",
        "    # We summarize each section that has been split up separately.\n",
        "    response = summarization(summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
        "\n",
        "    # Calculate the execution time and round it to 2 decimal places.\n",
        "    cost_time = round(time.time() - start, 2)\n",
        "\n",
        "    # Print the summary and its length.\n",
        "    print(f\"----------------------------Summary of Segment {index + 1}----------------------------\\n\")\n",
        "    for text in textwrap.wrap(response, 80):\n",
        "        print(f\"{text}\\n\")\n",
        "    print(f\"Length of summary for segment {index + 1}: {len(response)}\")\n",
        "    print(f\"Time taken to generate summary for segment {index + 1}: {cost_time} sec.\\n\")\n",
        "\n",
        "    # Record the result.\n",
        "    paragraph_summarizations.append(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amp-gOibmpvK"
      },
      "outputs": [],
      "source": [
        "# First, we collect all the summarizations obtained before and print them.\n",
        "\n",
        "collected_summarization = \"\"\n",
        "for index, paragraph_summarization in enumerate(paragraph_summarizations):\n",
        "    collected_summarization += f\"Summary of segment {index + 1}: {paragraph_summarization}\\n\"\n",
        "\n",
        "print(collected_summarization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y08WjQxiuZ0k"
      },
      "source": [
        "#####Step2: After obtaining summaries for each smaller text piece separately, process these summaries to generate the final summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4GEhPEIudBe"
      },
      "outputs": [],
      "source": [
        "# @title Prompt Setting of Gemini Multi-Stage Summarization: Total { run: \"auto\" }\n",
        "''' You can modify the summarization prompt and maximum number of tokens. '''\n",
        "''' However, DO NOT modify the part of <text>.'''\n",
        "\n",
        "# We set the maximum number of tokens to ensure that the final summary does not exceed 550 tokens.\n",
        "# @markdown **max_tokens**: We set the maximum number of tokens to ensure that the final summary does not exceed 550 tokens.\n",
        "max_tokens = 550 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown ### Changing **summarization_prompt_template**\n",
        "# @markdown You can modify the summarization prompt and maximum number of tokens. However, **DO NOT** modify the part of `<text>`.\n",
        "summarization_prompt_template = \"在 500 字以內寫出以下文字的簡潔摘要：<text>\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdTjmyvfZwar"
      },
      "source": [
        "The code block below takes about **20** seconds to run when using the (1) **gemini-pro** model, (2) length of chunks is 512 and (3) maximum number of tokens is 550, but the actual time may vary depending on the condition of Colab and the status of the Google API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6x5fn6I-msGC"
      },
      "outputs": [],
      "source": [
        "# Finally, we compile a final summary from the summaries of each section.\n",
        "\n",
        "# Record the start time.\n",
        "start = time.time()\n",
        "\n",
        "# Run final summarization.\n",
        "summarization_prompt = summarization_prompt_template.replace(\"<text>\", collected_summarization)\n",
        "final_summarization = summarization(summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
        "\n",
        "# Calculate the execution time and round it to 2 decimal places.\n",
        "cost_time = round(time.time() - start, 2)\n",
        "\n",
        "# Print the summary and its length.\n",
        "print(f\"----------------------------Final Summary----------------------------\\n\")\n",
        "for text in textwrap.wrap(final_summarization, 80):\n",
        "        print(f\"{text}\")\n",
        "print(f\"\\nLength of final summary: {len(final_summarization)}\")\n",
        "print(f\"Time taken to generate the final summary: {cost_time} sec.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPR2Am6omt0U"
      },
      "outputs": [],
      "source": [
        "''' In this block, you can modify your desired output path of final summary. '''\n",
        "\n",
        "output_path = f\"./final-summary-{suffix}-gemini-multi-stage.txt\"\n",
        "\n",
        "# If you need to convert Simplified Chinese to Traditional Chinese, please set this option to True; otherwise, set it to False.\n",
        "convert_to_tradition_chinese = False\n",
        "\n",
        "if convert_to_tradition_chinese == True:\n",
        "    # Creating an instance of OpenCC for Simplified to Traditional Chinese conversion.\n",
        "    cc = OpenCC('s2t')\n",
        "    final_summarization = cc.convert(final_summarization)\n",
        "\n",
        "# Output your final summary\n",
        "with open(output_path, \"w\") as fp:\n",
        "    fp.write(final_summarization)\n",
        "\n",
        "print(f\"Final summary has been saved to {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDZVeHCKvcMy"
      },
      "source": [
        "#### **If you want to use the method of Refinement, begin with this part.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1goEansHvc8C"
      },
      "outputs": [],
      "source": [
        "# @title Prompt Setting of Gemini Refinement { run: \"auto\" }\n",
        "''' You can modify the summarization prompt and maximum number of tokens. '''\n",
        "''' However, DO NOT modify the part of <text>.'''\n",
        "\n",
        "# We set the maximum number of tokens.\n",
        "# @markdown **max_tokens**: We set the maximum number of tokens.\n",
        "max_tokens = 550 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown ### Changing **summarization_prompt_template** and **summarization_prompt_refine_template**\n",
        "# @markdown You can modify the summarization prompt and maximum number of tokens. However, **DO NOT** modify the part of `<text>`.\n",
        "\n",
        "# Initial prompt.\n",
        "# @markdown **summarization_prompt_template**: Initial prompt.\n",
        "summarization_prompt_template = \"請在 300 字以內，提供以下文字的簡潔摘要:<text>\" # @param {type:\"string\"}\n",
        "\n",
        "# Refinement prompt.\n",
        "# @markdown **summarization_prompt_refinement_template**: Refinement prompt.\n",
        "summarization_prompt_refinement_template = \"請在 500 字以內，結合原先的摘要和新的內容，提供簡潔的摘要:<text>\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5AunhcUwDWh"
      },
      "source": [
        "Pipeline of the method of Refinement.\n",
        "\n",
        "Step1: It starts by running a prompt on a small portion of the data, generating initial output.\n",
        "\n",
        "Step2: For each following document, the previous output is fed in along with the new document.\n",
        "\n",
        "Step3: The LLM is instructed to refine the output based on the new document's information.\n",
        "\n",
        "Step4: This process continues iteratively until all documents have been processed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJMgqTC_2WD0"
      },
      "source": [
        "The code block below takes about **45** seconds to run when using the (1) **gemini-pro** model and (2) maximum number of tokens is 500, but the actual time may vary depending on the condition of Colab and the status of the Google API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDWW_K4OwG1N"
      },
      "outputs": [],
      "source": [
        "paragraph_summarizations = []\n",
        "\n",
        "# First, we summarize each section that has been split up separately.\n",
        "for index, chunk in enumerate(chunks):\n",
        "\n",
        "    if index == 0:\n",
        "        # Record the start time.\n",
        "        start = time.time()\n",
        "\n",
        "        # Construct summarization prompt.\n",
        "        summarization_prompt = summarization_prompt_template.replace(\"<text>\", chunk)\n",
        "\n",
        "        # Step1: It starts by running a prompt on a small portion of the data, generating initial output.\n",
        "        first_paragraph_summarization = summarization(summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
        "\n",
        "        # Record the result.\n",
        "        paragraph_summarizations.append(first_paragraph_summarization)\n",
        "\n",
        "        # Calculate the execution time and round it to 2 decimal places.\n",
        "        cost_time = round(time.time() - start, 2)\n",
        "\n",
        "        # Print the summary and its length.\n",
        "        print(f\"----------------------------Summary of Segment {index + 1}----------------------------\\n\")\n",
        "        for text in textwrap.wrap(first_paragraph_summarization, 80):\n",
        "            print(f\"{text}\\n\")\n",
        "        print(f\"Length of summary for segment {index + 1}: {len(first_paragraph_summarization)}\")\n",
        "        print(f\"Time taken to generate summary for segment {index + 1}: {cost_time} sec.\\n\")\n",
        "\n",
        "    else:\n",
        "        # Record the start time.\n",
        "        start = time.time()\n",
        "\n",
        "        # Step2: For each following document, the previous output is fed in along with the new document.\n",
        "        chunk_text = f\"\"\"前 {index} 段的摘要: {paragraph_summarizations[-1]}\\n第 {index + 1} 段的內容: {chunk}\"\"\"\n",
        "\n",
        "        # Construct refinement prompt for summarization.\n",
        "        summarization_prompt = summarization_prompt_refinement_template.replace(\"<text>\", chunk_text)\n",
        "\n",
        "        # Step3: The LLM is instructed to refine the output based on the new document's information.\n",
        "        paragraph_summarization = summarization(summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
        "\n",
        "        # Record the result.\n",
        "        paragraph_summarizations.append(paragraph_summarization)\n",
        "\n",
        "        # Calculate the execution time and round it to 2 decimal places.\n",
        "        cost_time = round(time.time() - start, 2)\n",
        "\n",
        "        # print results.\n",
        "        print(f\"----------------------------Summary of the First {index + 1} Segments----------------------------\\n\")\n",
        "        for text in textwrap.wrap(paragraph_summarization, 80):\n",
        "            print(f\"{text}\\n\")\n",
        "        print(f\"Length of summary for the first {index + 1} segments: {len(paragraph_summarization)}\")\n",
        "        print(f\"Time taken to generate summary for the first {index + 1} segments: {cost_time} sec.\\n\")\n",
        "\n",
        "    # Step4: This process continues iteratively until all documents have been processed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5jw0HwWwW83"
      },
      "outputs": [],
      "source": [
        "''' In this block, you can modify your desired output path of final summary. '''\n",
        "\n",
        "output_path = f\"./final-summary-{suffix}-gemini-refinement.txt\"\n",
        "\n",
        "# If you need to convert Simplified Chinese to Traditional Chinese, please set this option to True; otherwise, set it to False.\n",
        "convert_to_tradition_chinese = False\n",
        "\n",
        "if convert_to_tradition_chinese == True:\n",
        "    # Creating an instance of OpenCC for Simplified to Traditional Chinese conversion.\n",
        "    cc = OpenCC('s2t')\n",
        "    paragraph_summarizations[-1] = cc.convert(paragraph_summarizations[-1])\n",
        "\n",
        "# Output your final summary\n",
        "with open(output_path, \"w\") as fp:\n",
        "    fp.write(paragraph_summarizations[-1])\n",
        "\n",
        "# Show the result.\n",
        "print(f\"Final summary has been saved to {output_path}\")\n",
        "print(f\"\\n===== Below is the final summary ({len(paragraph_summarizations[-1])} words) =====\\n\")\n",
        "for text in textwrap.wrap(paragraph_summarizations[-1], 64):\n",
        "    print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3rwvZYdXieB"
      },
      "source": [
        "## **If you want to use Claude, begin with this part.**\n",
        "##### (1) You can refer to https://reurl.cc/yLy06D for obtaining Claude API key.\n",
        "##### (2) You can refer to https://docs.anthropic.com/claude/docs/models-overview for more details about which models you can use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-51sj3lXieC"
      },
      "outputs": [],
      "source": [
        "def summarization(client, summarization_prompt, model_name=\"claude-3-sonnet-20240229\", temperature=0.0, top_p=1.0, max_tokens=512):\n",
        "    \"\"\"\n",
        "    (1) Objective:\n",
        "        - Use the Claude API to summarize a given text.\n",
        "\n",
        "    (2) Arguments:\n",
        "        - client: Claude API client.\n",
        "        - text: The text to be summarized.\n",
        "        - summarization_prompt: The summarization prompt.\n",
        "        - model_name: The model name, default is \"claude-3-sonnet-20240229\". You can refer to \"https://docs.anthropic.com/claude/docs/models-overview#model-comparison\" for more details.\n",
        "        - temperature: Controls randomness in the response. Lower values make responses more deterministic, default is 0.0.\n",
        "        - top_p: Controls diversity via nucleus sampling. Higher values lead to more diverse responses, default is 1.0.\n",
        "        - max_tokens: The maximum number of tokens to generate in the completion, default is 512.\n",
        "\n",
        "    (3) Return:\n",
        "        - The summarized text.\n",
        "\n",
        "    (4) Example:\n",
        "        - If the text is \"ABC\" and the summarization prompt is \"DEF\", system_prompt is \"GHI\", model_name is \"claude-3-sonnet-20240229\",\n",
        "          temperature is 0.0, top_p is 1.0, and max_tokens is 512, then you can call the function like this:\n",
        "\n",
        "              summarization(client=client, text=\"ABC\", summarization_prompt=\"DEF\", system_prompt=\"GHI\", model_name=\"claude-3-sonnet-20240229\", temperature=0.0, top_p=1.0, max_tokens=512)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    user_prompt = summarization_prompt\n",
        "\n",
        "    while True:\n",
        "\n",
        "        try:\n",
        "            # Use the Claude API to summarize the text.\n",
        "            message = client.messages.create(\n",
        "                model=model_name,\n",
        "                max_tokens=max_tokens,\n",
        "                temperature=temperature,\n",
        "                messages=[\n",
        "                    {\"role\": \"user\", \"content\": user_prompt}\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            break\n",
        "\n",
        "        except:\n",
        "            # If the API call fails, wait for 1 second and try again.\n",
        "            print(\"The API call fails, wait for 1 second and try again.\")\n",
        "            time.sleep(1)\n",
        "\n",
        "    return message.content[0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1mfcYh1Rwkrh"
      },
      "outputs": [],
      "source": [
        "# @title Parameter Setting of Claude { run: \"auto\" }\n",
        "''' ===== In this block, you can modify your desired parameters and set your Claude API key ===== '''\n",
        "\n",
        "# Your Claude API key.\n",
        "# @markdown **claude_api_key**: Your Claude api key.\n",
        "claude_api_key = \"YOUR_CLAUDE_API_KEY\" # @param {type:\"string\"}\n",
        "\n",
        "# The model name, default is \"claude-3-opus-20240229\". You can refer to \"https://docs.anthropic.com/claude/docs/models-overview#model-comparison\" for more details.\n",
        "# @markdown **model_name**: The model name, default is \"claude-3-opus-20240229\". You can refer to \"https://docs.anthropic.com/claude/docs/models-overview#model-comparison\" for more details.\n",
        "model_name = \"claude-3-opus-20240229\" # @param {type:\"string\"}\n",
        "\n",
        "# Controls randomness in the response. Lower values make responses more deterministic.\n",
        "# @markdown **temperature**: Controls randomness in the response. Lower values make responses more deterministic.\n",
        "temperature = 1 # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "\n",
        "# Controls diversity via nucleus sampling. Higher values lead to more diverse responses.\n",
        "# @markdown **top_p**: Controls diversity via nucleus sampling. Higher values lead to more diverse responses.\n",
        "top_p = 1.0 # @param {type:\"slider\", min:0, max:1, step:0.1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-ivbHl6wrIj"
      },
      "outputs": [],
      "source": [
        "# Construct Claude client.\n",
        "client = anthropic.Anthropic(api_key=claude_api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eDZJpX7xagQ"
      },
      "source": [
        "### We offer the following two methods for summarization.\n",
        "Reference: https://reurl.cc/VzagLA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEmYimdXxctB"
      },
      "source": [
        "#### **If you want to use the method of Multi-Stage Summarization, begin with this part.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4OBcswSxfUp"
      },
      "outputs": [],
      "source": [
        "# @title Prompt Setting of Claude Multi-Stage Summarization: Paragraph { run: \"auto\" }\n",
        "''' You can modify the summarization prompt and maximum number of tokens. '''\n",
        "''' However, DO NOT modify the part of <text>.'''\n",
        "\n",
        "# The maximum number of tokens to generate in the completion.\n",
        "# @markdown **max_tokens**: The maximum number of tokens to generate in the completion.\n",
        "max_tokens = 350 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown #### Changing **summarization_prompt_template**\n",
        "# @markdown You can modify the summarization prompt and maximum number of tokens. However, **DO NOT** modify the part of `<text>`.\n",
        "summarization_prompt_template = \"用 300 個字內寫出這段文字的摘要，其中包括要點和所有重要細節：<text>\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WClFqWBsyUWB"
      },
      "source": [
        "##### Step1: Split the long text into multiple smaller pieces and obtain summaries for each smaller text piece separately"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avQs_YFg2mK7"
      },
      "source": [
        "The code block below takes about **120** seconds to run when using the (1) **claude-3-opus-20240229** model, (2) length of chunks is 512 and (3) maximum number of tokens is 350, but the actual time may vary depending on the condition of Colab and the status of the Claude API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJlEpq4EqIAN"
      },
      "outputs": [],
      "source": [
        "paragraph_summarizations = []\n",
        "\n",
        "# First, we summarize each section that has been split up separately.\n",
        "for index, chunk in enumerate(chunks):\n",
        "\n",
        "    # Record the start time.\n",
        "    start = time.time()\n",
        "\n",
        "    # Construct summarization prompt.\n",
        "    summarization_prompt = summarization_prompt_template.replace(\"<text>\", chunk)\n",
        "\n",
        "    # We summarize each section that has been split up separately.\n",
        "    response = summarization(client=client, summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
        "\n",
        "    # Calculate the execution time and round it to 2 decimal places.\n",
        "    cost_time = round(time.time() - start, 2)\n",
        "\n",
        "    # Print the summary and its length.\n",
        "    print(f\"----------------------------Summary of Segment {index + 1}----------------------------\\n\")\n",
        "    for text in textwrap.wrap(response, 80):\n",
        "        print(f\"{text}\\n\")\n",
        "    print(f\"Length of summary for segment {index + 1}: {len(response)}\")\n",
        "    print(f\"Time taken to generate summary for segment {index + 1}: {cost_time} sec.\\n\")\n",
        "\n",
        "    # Record the result.\n",
        "    paragraph_summarizations.append(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vzgd8rWqJP9"
      },
      "outputs": [],
      "source": [
        "# First, we collect all the summarizations obtained before and print them.\n",
        "\n",
        "collected_summarization = \"\"\n",
        "for index, paragraph_summarization in enumerate(paragraph_summarizations):\n",
        "    collected_summarization += f\"Summary of segment {index + 1}: {paragraph_summarization}\\n\\n\"\n",
        "\n",
        "print(collected_summarization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qDxoyLpymA5"
      },
      "source": [
        "##### Step2: After obtaining summaries for each smaller text piece separately, process these summaries to generate the final summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E99bQfbgynXT"
      },
      "outputs": [],
      "source": [
        "# @title Prompt Setting of Gemini Multi-Stage Summarization: Total { run: \"auto\" }\n",
        "''' You can modify the summarization prompt and maximum number of tokens. '''\n",
        "''' However, DO NOT modify the part of <text>.'''\n",
        "\n",
        "# We set the maximum number of tokens to ensure that the final summary does not exceed 550 tokens.\n",
        "# @markdown **max_tokens**: We set the maximum number of tokens to ensure that the final summary does not exceed 550 tokens.\n",
        "max_tokens = 550 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown ### Changing **summarization_prompt_template**\n",
        "# @markdown You can modify the summarization prompt and maximum number of tokens. However, **DO NOT** modify the part of `<text>`.\n",
        "summarization_prompt_template = \"在 500 字以內寫出以下文字的簡潔摘要：<text>\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-WvuFl4XV2J"
      },
      "source": [
        "The code block below takes about **25** seconds to run when using the (1) **claude-3-opus-20240229** model, (2) length of chunks is 512 and (3) maximum number of tokens is 550, but the actual time may vary depending on the condition of Colab and the status of the Claude API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qX4pa5QqKrc"
      },
      "outputs": [],
      "source": [
        "# Finally, we compile a final summary from the summaries of each section.\n",
        "\n",
        "# Record the start time.\n",
        "start = time.time()\n",
        "\n",
        "summarization_prompt = summarization_prompt_template.replace(\"<text>\", collected_summarization)\n",
        "\n",
        "# Run final summarization.\n",
        "final_summarization = summarization(client=client, summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
        "\n",
        "# Calculate the execution time and round it to 2 decimal places.\n",
        "cost_time = round(time.time() - start, 2)\n",
        "\n",
        "# Print the summary and its length.\n",
        "print(f\"----------------------------Final Summary----------------------------\\n\")\n",
        "for text in textwrap.wrap(final_summarization, 80):\n",
        "    print(f\"{text}\")\n",
        "print(f\"\\nLength of final summary: {len(final_summarization)}\")\n",
        "print(f\"Time taken to generate the final summary: {cost_time} sec.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldTq9WYlqL2U"
      },
      "outputs": [],
      "source": [
        "''' In this block, you can modify your desired output path of final summary. '''\n",
        "\n",
        "output_path = f\"./final-summary-{suffix}-claude-multi-stage.txt\"\n",
        "\n",
        "# If you need to convert Simplified Chinese to Traditional Chinese, please set this option to True; otherwise, set it to False.\n",
        "convert_to_tradition_chinese = False\n",
        "\n",
        "if convert_to_tradition_chinese == True:\n",
        "    # Creating an instance of OpenCC for Simplified to Traditional Chinese conversion.\n",
        "    cc = OpenCC('s2t')\n",
        "    final_summarization = cc.convert(final_summarization)\n",
        "\n",
        "# Output your final summary\n",
        "with open(output_path, \"w\") as fp:\n",
        "    fp.write(final_summarization)\n",
        "\n",
        "# Show the result.\n",
        "print(f\"Final summary has been saved to {output_path}\")\n",
        "print(f\"\\n===== Below is the final summary ({len(final_summarization)} words) =====\\n\")\n",
        "for text in textwrap.wrap(final_summarization, 64):\n",
        "    print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBI-Ba8QzLU8"
      },
      "source": [
        "#### **If you want to use the method of Refinement, begin with this part.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-t2muOwUzNd0"
      },
      "outputs": [],
      "source": [
        "# @title Prompt Setting of Claude Refinement { run: \"auto\" }\n",
        "''' You can modify the summarization prompt and maximum number of tokens. '''\n",
        "''' However, DO NOT modify the part of <text>.'''\n",
        "\n",
        "# We set the maximum number of tokens.\n",
        "# @markdown **max_tokens**: We set the maximum number of tokens.\n",
        "max_tokens = 550 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown ### Changing **summarization_prompt_template** and **summarization_prompt_refine_template**\n",
        "# @markdown You can modify the summarization prompt and maximum number of tokens. However, **DO NOT** modify the part of `<text>`.\n",
        "\n",
        "# Initial prompt.\n",
        "# @markdown **summarization_prompt_template**: Initial prompt.\n",
        "summarization_prompt_template = \"請在 300 字以內，提供以下文字的簡潔摘要:<text>\" # @param {type:\"string\"}\n",
        "\n",
        "# Refinement prompt.\n",
        "# @markdown **summarization_prompt_refinement_template**: Refinement prompt.\n",
        "summarization_prompt_refinement_template = \"請在 500 字以內，結合原先的摘要和新的內容，提供簡潔的摘要:<text>\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JxW1AR2zZDL"
      },
      "source": [
        "Pipeline of the method of Refinement.\n",
        "\n",
        "Step1: It starts by running a prompt on a small portion of the data, generating initial output.\n",
        "\n",
        "Step2: For each following document, the previous output is fed in along with the new document.\n",
        "\n",
        "Step3: The LLM is instructed to refine the output based on the new document's information.\n",
        "\n",
        "Step4: This process continues iteratively until all documents have been processed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkm60apd2tQd"
      },
      "source": [
        "The code block below takes about **150** seconds to run when using the (1) **claude-3-opus-20240229** model and (2) maximum number of tokens is 500, but the actual time may vary depending on the condition of Colab and the status of the Claude API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Feco4LK4zazs"
      },
      "outputs": [],
      "source": [
        "paragraph_summarizations = []\n",
        "\n",
        "# First, we summarize each section that has been split up separately.\n",
        "for index, chunk in enumerate(chunks):\n",
        "\n",
        "    if index == 0:\n",
        "        # Record the start time.\n",
        "        start = time.time()\n",
        "\n",
        "        # Construct summarization prompt.\n",
        "        summarization_prompt = summarization_prompt_template.replace(\"<text>\", chunk)\n",
        "\n",
        "        # Step1: It starts by running a prompt on a small portion of the data, generating initial output.\n",
        "        first_paragraph_summarization = summarization(client=client, summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
        "\n",
        "        # Record the result.\n",
        "        paragraph_summarizations.append(first_paragraph_summarization)\n",
        "\n",
        "        # Calculate the execution time and round it to 2 decimal places.\n",
        "        cost_time = round(time.time() - start, 2)\n",
        "\n",
        "        # Print the summary and its length.\n",
        "        print(f\"----------------------------Summary of Segment {index + 1}----------------------------\\n\")\n",
        "        for text in textwrap.wrap(response, 80):\n",
        "            print(f\"{text}\\n\")\n",
        "        print(f\"Length of summary for segment {index + 1}: {len(response)}\")\n",
        "        print(f\"Time taken to generate summary for segment {index + 1}: {cost_time} sec.\\n\")\n",
        "\n",
        "\n",
        "    else:\n",
        "        # Record the start time.\n",
        "        start = time.time()\n",
        "\n",
        "        # Step2: For each following document, the previous output is fed in along with the new document.\n",
        "        chunk_text = f\"\"\"前 {index} 段的摘要: {paragraph_summarizations[-1]}\\n第 {index + 1} 段的內容: {chunk}\"\"\"\n",
        "\n",
        "        # Construct refinement prompt for summarization.\n",
        "        summarization_prompt = summarization_prompt_refinement_template.replace(\"<text>\", chunk_text)\n",
        "\n",
        "        # Step3: The LLM is instructed to refine the output based on the new document's information.\n",
        "        paragraph_summarization = summarization(client=client, summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
        "\n",
        "        # Record the result.\n",
        "        paragraph_summarizations.append(paragraph_summarization)\n",
        "\n",
        "        # Calculate the execution time and round it to 2 decimal places.\n",
        "        cost_time = round(time.time() - start, 2)\n",
        "\n",
        "        # print results.\n",
        "        print(f\"----------------------------Summary of the First {index + 1} Segments----------------------------\\n\")\n",
        "        for text in textwrap.wrap(paragraph_summarization, 80):\n",
        "            print(f\"{text}\\n\")\n",
        "        print(f\"Length of summary for the first {index + 1} segments: {len(paragraph_summarization)}\")\n",
        "        print(f\"Time taken to generate summary for the first {index + 1} segments: {cost_time} sec.\\n\")\n",
        "\n",
        "    # Step4: This process continues iteratively until all documents have been processed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4BGRgvFz0eW"
      },
      "outputs": [],
      "source": [
        "''' In this block, you can modify your desired output path of final summary. '''\n",
        "\n",
        "output_path = f\"./final-summary-{suffix}-claude-refinement.txt\"\n",
        "\n",
        "# If you need to convert Simplified Chinese to Traditional Chinese, please set this option to True; otherwise, set it to False.\n",
        "convert_to_tradition_chinese = False\n",
        "\n",
        "if convert_to_tradition_chinese == True:\n",
        "    # Creating an instance of OpenCC for Simplified to Traditional Chinese conversion.\n",
        "    cc = OpenCC('s2t')\n",
        "    paragraph_summarizations[-1] = cc.convert(paragraph_summarizations[-1])\n",
        "\n",
        "# Output your final summary\n",
        "with open(output_path, \"w\") as fp:\n",
        "    fp.write(paragraph_summarizations[-1])\n",
        "\n",
        "# Show the result.\n",
        "print(f\"Final summary has been saved to {output_path}\")\n",
        "print(f\"\\n===== Below is the final summary ({len(paragraph_summarizations[-1])} words) =====\\n\")\n",
        "for text in textwrap.wrap(paragraph_summarizations[-1], 80):\n",
        "    print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtQoyYjfdQLC"
      },
      "source": [
        "# Part5 - Check the correctness of the submission file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gclg3cORdiVR",
        "outputId": "ba037610-32ab-4da2-c349-888660273ca1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The format of your submission file is correct.\n",
            "Your final score is 99.\n"
          ]
        }
      ],
      "source": [
        "# Check the correctness of the submission file.\n",
        "import json\n",
        "import re\n",
        "\n",
        "your_submission_path = \"/content/r12942159.json\"\n",
        "\n",
        "\n",
        "def check_format(your_submission_path):\n",
        "\n",
        "    final_score = 0\n",
        "\n",
        "    # check the extension of the file.\n",
        "    if not your_submission_path.endswith(\".json\"):\n",
        "        print(\"Please save your submission file in JSON format.\")\n",
        "        return False, final_score\n",
        "    else:\n",
        "        try:\n",
        "            with open(your_submission_path, \"r\") as fp:\n",
        "                your_submission = json.load(fp)\n",
        "\n",
        "            evaluation_result = your_submission[\"history\"][0][\"messages\"][1][\"content\"]\n",
        "\n",
        "            if \"總分：\" not in evaluation_result:\n",
        "                # Correct format: 總分: <你的分數>\n",
        "                print(\"Please make sure that the correct format of final score is included in the evaluation result.\")\n",
        "                print(\"The correct format is 總分: <你的分數>. For example, 總分: 97\")\n",
        "                return False, final_score\n",
        "\n",
        "            evaluation_result = evaluation_result.strip()\n",
        "            score_pattern = r\"總分：\\d+\"\n",
        "            score = re.findall(score_pattern, evaluation_result)\n",
        "\n",
        "            if score:\n",
        "                final_score = score[-1].replace(\"總分：\", \"\")\n",
        "                if \"/100\" in final_score:\n",
        "                    final_score = final_score.replace(\"/100\", \"\")\n",
        "            else:\n",
        "                print(\"Please make sure that the final score is included in the evaluation result.\")\n",
        "                return False, final_score\n",
        "\n",
        "        except:\n",
        "            print(\"Open the file failed. Please check the file path or save your submission file in correct JSON format\")\n",
        "            return False, final_score\n",
        "\n",
        "    return True, final_score\n",
        "\n",
        "format_correctness, final_score = check_format(your_submission_path)\n",
        "if format_correctness== True:\n",
        "    print(\"The format of your submission file is correct.\")\n",
        "    print(f\"Your final score is {final_score}.\")\n",
        "else:\n",
        "    print(\"The format of your submission file is wrong.\")\n",
        "    print(\"Please check the format of your submission file.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjM8Dc5HEJes"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "z9QC8lG_QRZL",
        "hRzf_0cTV6TS",
        "GEmYimdXxctB",
        "eBI-Ba8QzLU8"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "006bb78e1a1a4456a25295caea262d63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "099dd6a79fee42a28d39cfb0984d1494": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_efad0a1f7bf7412ba39d488428593af3",
              "IPY_MODEL_fc78c9ef37544f26aa45ec4ae4ad0501",
              "IPY_MODEL_86c2f797ac92442f93e80b390e6b70ad"
            ],
            "layout": "IPY_MODEL_e9f84e42a9f645258245f40e71d6f4c3"
          }
        },
        "1c07953785b94210a1503cc3aa7e917f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25d42064d33b49199a378017d46ea26a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f40912e59ad45eeb337a62ed8ab0d79": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40b44a98ac144c2794a585e0903eb960": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d261d016c5e34bb998b2f60a46681fc4",
            "max": 3140168,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfdd4956c6244dfba7e524878532bb12",
            "value": 3140168
          }
        },
        "4a294271842a465c9843b1e0b4d55b2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c323eec317a4cc283b7533ef25a4592": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62829631d64b4402bd8d0185b268bf5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cd53057125b4dbd9885d5458e03ebbf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70800a5fbfe4436d82c428733a16aa60": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71cb28a87d46426c94b97b0dfa37a2f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70800a5fbfe4436d82c428733a16aa60",
            "placeholder": "​",
            "style": "IPY_MODEL_25d42064d33b49199a378017d46ea26a",
            "value": "Downloading readme: 100%"
          }
        },
        "72117f7544e441b38d5d910af445d785": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3f62551a707485fab72d240fc4f8fe7",
              "IPY_MODEL_40b44a98ac144c2794a585e0903eb960",
              "IPY_MODEL_7ba16a3b19284863b52a0a3ba04bd668"
            ],
            "layout": "IPY_MODEL_fa6f5e5f15854517851c141aaba69fec"
          }
        },
        "725f3b88f2fd4df2b38d76dbab599165": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73e610aefcb24297b7798eea993d7a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71cb28a87d46426c94b97b0dfa37a2f9",
              "IPY_MODEL_ff8f1eef385a4e1d9edb79149f997488",
              "IPY_MODEL_c0ec8184773a4aaa912316b8d350445b"
            ],
            "layout": "IPY_MODEL_6cd53057125b4dbd9885d5458e03ebbf"
          }
        },
        "76ce9f593f174606842a56fcbd8b3fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ba16a3b19284863b52a0a3ba04bd668": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b91d12ab1e114995be5063c3107f0bfb",
            "placeholder": "​",
            "style": "IPY_MODEL_62829631d64b4402bd8d0185b268bf5f",
            "value": " 3.14M/3.14M [00:00&lt;00:00, 8.37MB/s]"
          }
        },
        "8659b492a8404f86b1eb8b83a6af1678": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86c2f797ac92442f93e80b390e6b70ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f40912e59ad45eeb337a62ed8ab0d79",
            "placeholder": "​",
            "style": "IPY_MODEL_5c323eec317a4cc283b7533ef25a4592",
            "value": " 1/1 [00:00&lt;00:00, 13.60 examples/s]"
          }
        },
        "9c472c36419744d996c8ad05f662526b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adf3e275a67c4ce39dc09abbba201358": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b91d12ab1e114995be5063c3107f0bfb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0ec8184773a4aaa912316b8d350445b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_725f3b88f2fd4df2b38d76dbab599165",
            "placeholder": "​",
            "style": "IPY_MODEL_9c472c36419744d996c8ad05f662526b",
            "value": " 305/305 [00:00&lt;00:00, 11.5kB/s]"
          }
        },
        "cfdd4956c6244dfba7e524878532bb12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d261d016c5e34bb998b2f60a46681fc4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dac72638b91a4a2b9bda90cb2793e8d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3f62551a707485fab72d240fc4f8fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a294271842a465c9843b1e0b4d55b2f",
            "placeholder": "​",
            "style": "IPY_MODEL_006bb78e1a1a4456a25295caea262d63",
            "value": "Downloading data: 100%"
          }
        },
        "e4d0bdf7c9424aa399d26c66af28f938": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9f84e42a9f645258245f40e71d6f4c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efad0a1f7bf7412ba39d488428593af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dac72638b91a4a2b9bda90cb2793e8d1",
            "placeholder": "​",
            "style": "IPY_MODEL_8659b492a8404f86b1eb8b83a6af1678",
            "value": "Generating test split: 100%"
          }
        },
        "fa6f5e5f15854517851c141aaba69fec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc78c9ef37544f26aa45ec4ae4ad0501": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c07953785b94210a1503cc3aa7e917f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adf3e275a67c4ce39dc09abbba201358",
            "value": 1
          }
        },
        "ff8f1eef385a4e1d9edb79149f997488": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4d0bdf7c9424aa399d26c66af28f938",
            "max": 305,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76ce9f593f174606842a56fcbd8b3fa7",
            "value": 305
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
